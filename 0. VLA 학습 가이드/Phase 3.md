# VLA ÌïôÏäµ Í∞ÄÏù¥Îìú - Phase 3

## Î™©Ï∞®
- [üìÖ Phase 3: Isaac Sim Î≥∏Í≤© ÌîÑÎ°úÏ†ùÌä∏ (7-12Í∞úÏõî)](#-phase-3-isaac-sim-Î≥∏Í≤©-ÌîÑÎ°úÏ†ùÌä∏-7-12Í∞úÏõî)
- [Month 7-8: Isaac Sim & ROS2 ÌÜµÌï©](#month-7-8-isaac-sim--ros2-ÌÜµÌï©)
  - [Week 1-2: Isaac Sim Í∏∞Ï¥à](#week-1-2-isaac-sim-Í∏∞Ï¥à)
  - [Week 3-4: Î°úÎ¥á Ï†úÏñ¥](#week-3-4-Î°úÎ¥á-Ï†úÏñ¥)
  - [Week 5-8: Î¨ºÎ•ò ÌôòÍ≤Ω Íµ¨Ï∂ï](#week-5-8-Î¨ºÎ•ò-ÌôòÍ≤Ω-Íµ¨Ï∂ï)
- [Month 9: Action & Observation Space ÏÑ§Í≥Ñ](#month-9-action--observation-space-ÏÑ§Í≥Ñ)
  - [Week 1: Action Space ÏÑ§Í≥Ñ ‚ö†Ô∏è Îß§Ïö∞ Ï§ëÏöî!](#week-1-action-space-ÏÑ§Í≥Ñ-Ô∏è-Îß§Ïö∞-Ï§ëÏöî)
  - [Week 2: Observation Space ÏÑ§Í≥Ñ](#week-2-observation-space-ÏÑ§Í≥Ñ)
- [Month 10: Ï≤´ Î¨ºÎ•ò VLA Í∞úÎ∞ú](#month-10-Ï≤´-Î¨ºÎ•ò-vla-Í∞úÎ∞ú)
  - [Week 1-2: Îç∞Ïù¥ÌÑ∞ ÏàòÏßë & ÌíàÏßà Í¥ÄÎ¶¨](#week-1-2-Îç∞Ïù¥ÌÑ∞-ÏàòÏßë--ÌíàÏßà-Í¥ÄÎ¶¨)
  - [Week 3-4: VLA ÌïôÏäµ](#week-3-4-vla-ÌïôÏäµ)
  - [Week 5-6: ÌèâÍ∞Ä Î∞è ÎîîÎ≤ÑÍπÖ](#week-5-6-ÌèâÍ∞Ä-Î∞è-ÎîîÎ≤ÑÍπÖ)
- [Month 11-12: Í≥†ÎèÑÌôî Î∞è ROS2 ÌÜµÌï©](#month-11-12-Í≥†ÎèÑÌôî-Î∞è-ros2-ÌÜµÌï©)
  - [Week 1-2: Ïã§Ìå® Î≥µÍµ¨ ÏãúÏä§ÌÖú](#week-1-2-Ïã§Ìå®-Î≥µÍµ¨-ÏãúÏä§ÌÖú)
  - [Week 3-4: Safety Layer](#week-3-4-safety-layer)
  - [Week 5-6: ROS2 ÏôÑÏ†Ñ ÌÜµÌï©](#week-5-6-ros2-ÏôÑÏ†Ñ-ÌÜµÌï©)
  - [Week 7-8: Sim-to-Real Transfer Ï§ÄÎπÑ](#week-7-8-sim-to-real-transfer-Ï§ÄÎπÑ)
- [Real Robot Deployment Checklist](#real-robot-deployment-checklist)
- [Phase 3 ÏôÑÎ£å Ï≤¥ÌÅ¨](#phase-3-ÏôÑÎ£å-Ï≤¥ÌÅ¨)

## üìÖ Phase 3: Isaac Sim Î≥∏Í≤© ÌîÑÎ°úÏ†ùÌä∏ (7-12Í∞úÏõî)

### Î™©Ìëú
- Isaac Sim ÌôòÍ≤Ω ÎßàÏä§ÌÑ∞
- Î¨ºÎ•ò Î°úÎ¥á VLA Í∞úÎ∞ú
- ROS2 ÏôÑÏ†Ñ ÌÜµÌï©
- ÌòÑÏû• Ï†ÅÏö© Í∞ÄÎä•Ìïú ÏàòÏ§Ä
- Sim-to-Real Ï§ÄÎπÑ

---

## Month 7-8: Isaac Sim & ROS2 ÌÜµÌï©

### Week 1-2: Isaac Sim Í∏∞Ï¥à

#### ÏÑ§Ïπò Î∞è ÌôòÍ≤Ω Íµ¨Ï∂ï
```bash
# Isaac Sim ÏÑ§Ïπò (Í≥µÏãù Í∞ÄÏù¥Îìú Îî∞Îùº)
# https://docs.omniverse.nvidia.com/app_isaacsim/

# ÏãúÏä§ÌÖú ÏöîÍµ¨ÏÇ¨Ìï≠:
# - GPU: RTX 4070 (Ï∂©Î∂Ñ!)
# - RAM: 32GB (Í∂åÏû•)
# - Storage: 50GB+

# ROS2 Ïó∞Îèô ÌôïÏù∏
# Ubuntu 22.04 + ROS2 Humble
```

---

#### Í∏∞Î≥∏ ÌäúÌÜ†Î¶¨Ïñº ÏôÑÏ£º

**Hello World**
```python
# hello_world.py
from omni.isaac.kit import SimulationApp

# Launch Isaac Sim
simulation_app = SimulationApp({"headless": False})

from omni.isaac.core import World
from omni.isaac.core.objects import DynamicCuboid

# Create world
world = World()

# Add cube
cube = DynamicCuboid(
    prim_path="/World/Cube",
    position=[0, 0, 0.5],
    size=0.1,
    color=[1.0, 0.0, 0.0]
)

# Simulation loop
for i in range(1000):
    world.step(render=True)
    
    # Print cube position
    if i % 100 == 0:
        position, _ = cube.get_world_pose()
        print(f"Step {i}: Position = {position}")

simulation_app.close()
```

**Ï≤¥ÌÅ¨:**
- [ ] Isaac Sim GUI Ïó¥Î¶º
- [ ] CubeÍ∞Ä Îñ®Ïñ¥Ïßê
- [ ] Î¨ºÎ¶¨ ÏãúÎÆ¨Î†àÏù¥ÏÖò ÏûëÎèô

---

#### ÌïôÏäµ Ï£ºÏ†ú

**1. USD (Universal Scene Description)**
```python
"""
USDÎäî Isaac SimÏùò Í∏∞Î≥∏ scene Ìè¨Îß∑

ÌïµÏã¨ Í∞úÎÖê:
- Prim: SceneÏùò Í∏∞Î≥∏ Îã®ÏúÑ (object, light, camera Îì±)
- Stage: Î™®Îì† PrimÏùÑ Îã¥Îäî Ïª®ÌÖåÏù¥ÎÑà
- Layer: SceneÏùò hierarchical composition

Ïòà: /World/Robot/Link1
"""

# USD ÏßÅÏ†ë Ï°∞Ïûë
from pxr import Usd, UsdGeom

stage = omni.usd.get_context().get_stage()

# Create sphere
sphere_prim = UsdGeom.Sphere.Define(stage, "/World/Sphere")
sphere_prim.GetRadiusAttr().Set(0.5)

# Set position
sphere_prim.AddTranslateOp().Set((0, 0, 1))
```

**2. Physics Simulation ÏÑ§Ï†ï**
```python
from omni.isaac.core.utils.physics import simulate_async

# Physics scene ÏÑ§Ï†ï
scene = world.scene

# Gravity
scene.set_gravity([0, 0, -9.81])

# Physics parameters
world.get_physics_context().set_solver_type("TGS")  # Temporal Gauss-Seidel
world.get_physics_context().set_broadphase_type("GPU")

# Time step
world.set_simulation_dt(physics_dt=1.0/60.0, rendering_dt=1.0/60.0)
```

**3. Î†åÎçîÎßÅ ÏÑ§Ï†ï**
```python
# Rendering quality
import carb

settings = carb.settings.get_settings()

# Ray tracing
settings.set("/rtx/raytracing/enabled", True)
settings.set("/rtx/pathtracing/spp", 16)  # Samples per pixel

# Post-processing
settings.set("/rtx/post/aa/op", 2)  # Anti-aliasing
settings.set("/rtx/post/dlss/execMode", 1)  # DLSS
```

**ÏãúÍ∞Ñ: Ï£º 6-8ÏãúÍ∞Ñ**

---

### Week 3-4: Î°úÎ¥á Ï†úÏñ¥

#### Î™®Î∞îÏùº Î≤†Ïù¥Ïä§ + Îß§ÎãàÌì∞Î†àÏù¥ÌÑ∞
```python
# mobile_manipulator.py
from omni.isaac.wheeled_robots.robots import WheeledRobot
from omni.isaac.manipulators import SingleManipulator
from omni.isaac.core.articulations import Articulation

class MobileManipulator:
    """
    Î™®Î∞îÏùº Î≤†Ïù¥Ïä§ + Î°úÎ¥á Ìåî ÌÜµÌï©
    """
    
    def __init__(self, world):
        self.world = world
        
        # Load mobile base
        self.setup_mobile_base()
        
        # Load manipulator
        self.setup_manipulator()
        
        # Controllers
        self.setup_controllers()
    
    def setup_mobile_base(self):
        """
        Differential drive mobile base
        """
        from omni.isaac.wheeled_robots.controllers.differential_controller import DifferentialController
        
        # Add robot to scene
        self.base = self.world.scene.add(
            WheeledRobot(
                prim_path="/World/MobileBase",
                name="mobile_base",
                wheel_dof_names=["wheel_left_joint", "wheel_right_joint"],
                create_robot=True,
                usd_path="path/to/mobile_base.usd"
            )
        )
        
        # Controller
        self.base_controller = DifferentialController(
            name="base_controller",
            wheel_radius=0.1,
            wheel_base=0.5
        )
    
    def setup_manipulator(self):
        """
        6-DOF manipulator (e.g., UR5)
        """
        self.arm = self.world.scene.add(
            SingleManipulator(
                prim_path="/World/MobileBase/UR5",
                name="ur5",
                end_effector_prim_name="tool0",
                usd_path="path/to/ur5.usd"
            )
        )
        
        # Gripper
        from omni.isaac.manipulators.grippers import ParallelGripper
        
        self.gripper = self.world.scene.add(
            ParallelGripper(
                prim_path="/World/MobileBase/UR5/gripper",
                name="gripper"
            )
        )
    
    def setup_controllers(self):
        """
        Setup arm controller
        """
        from omni.isaac.manipulators.controllers import PickPlaceController
        
        self.arm_controller = PickPlaceController(
            name="pick_place_controller",
            gripper=self.gripper,
            robot_articulation=self.arm
        )
    
    def move_base(self, linear_velocity, angular_velocity):
        """
        Control mobile base
        
        Args:
            linear_velocity: m/s
            angular_velocity: rad/s
        """
        wheel_actions = self.base_controller.forward(
            command=[linear_velocity, angular_velocity]
        )
        self.base.apply_wheel_actions(wheel_actions)
    
    def move_arm(self, target_position, target_orientation=None):
        """
        Move arm to target pose
        
        Args:
            target_position: [x, y, z]
            target_orientation: [qx, qy, qz, qw] or None
        """
        actions = self.arm_controller.forward(
            picking_position=target_position,
            placing_position=None,
            current_joint_positions=self.arm.get_joint_positions()
        )
        self.arm.apply_action(actions)
    
    def control_gripper(self, action):
        """
        Control gripper
        
        Args:
            action: "open" or "close"
        """
        if action == "open":
            self.gripper.open()
        elif action == "close":
            self.gripper.close()

# ÏÇ¨Ïö© ÏòàÏãú
world = World()
robot = MobileManipulator(world)

# Simulation loop
for i in range(1000):
    # Move forward
    robot.move_base(linear_velocity=0.5, angular_velocity=0.0)
    
    # Move arm
    if i == 100:
        robot.move_arm(target_position=[0.5, 0.0, 0.5])
    
    if i == 200:
        robot.control_gripper("close")
    
    world.step(render=True)
```

---

#### ROS2 ÌÜµÌï©
```python
# ros2_integration.py
from omni.isaac.core.utils.extensions import enable_extension

# Enable ROS2 bridge
enable_extension("omni.isaac.ros2_bridge")

from omni.isaac.ros2_bridge import ROS2Bridge
import rclpy

class ROS2IntegratedRobot:
    """
    Isaac Sim ‚Üî ROS2 Î∏åÎ¶øÏßÄ
    """
    
    def __init__(self, robot):
        self.robot = robot
        self.bridge = ROS2Bridge()
        
        # Initialize ROS2
        rclpy.init()
        
        # Setup publishers/subscribers
        self.setup_ros2_interface()
    
    def setup_ros2_interface(self):
        """
        ROS2 topics ÏÑ§Ï†ï
        """
        # 1. Camera publisher
        self.camera_pub = self.bridge.add_camera_publisher(
            topic_name="/camera/image_raw",
            camera_prim_path="/World/Robot/Camera",
            message_type="sensor_msgs/Image",
            frame_id="camera_link"
        )
        
        # 2. Joint state publisher
        self.joint_state_pub = self.bridge.add_joint_state_publisher(
            topic_name="/joint_states",
            robot_prim_path="/World/Robot"
        )
        
        # 3. Odometry publisher
        self.odom_pub = self.bridge.add_odometry_publisher(
            topic_name="/odom",
            chassis_prim_path="/World/Robot/base_link"
        )
        
        # 4. Twist subscriber (velocity commands)
        self.twist_sub = self.bridge.add_twist_subscriber(
            topic_name="/cmd_vel",
            callback=self.twist_callback
        )
        
        # 5. Joint command subscriber
        self.joint_cmd_sub = self.bridge.add_subscriber(
            topic_name="/joint_commands",
            msg_type="sensor_msgs/JointState",
            callback=self.joint_callback
        )
    
    def twist_callback(self, msg):
        """
        Velocity command callback
        """
        linear = msg.linear.x
        angular = msg.angular.z
        
        self.robot.move_base(linear, angular)
    
    def joint_callback(self, msg):
        """
        Joint command callback
        """
        positions = msg.position
        self.robot.arm.set_joint_positions(positions)

# ÏÇ¨Ïö© ÏòàÏãú
robot = MobileManipulator(world)
ros2_robot = ROS2IntegratedRobot(robot)

# Simulation loop
while simulation_app.is_running():
    world.step(render=True)
    
    # ROS2 spin (process callbacks)
    rclpy.spin_once(ros2_robot.bridge.node, timeout_sec=0.0)
```

---

#### ROS2 Ìå®ÌÑ¥
```python
# lifecycle_robot_node.py
from rclpy.lifecycle import Node, State, TransitionCallbackReturn
from rclpy.lifecycle import Publisher, LifecycleState

class LifecycleRobotNode(Node):
    """
    Lifecycle Ìå®ÌÑ¥ ÌôúÏö©
    
   Í∏∞Ï°¥ ROS2 Í≤ΩÌóò ÌôúÏö©:
    - Lifecycle management
    - Diagnostics
    - tf2 transforms
    """
    
    def __init__(self, robot):
        super().__init__('vla_robot_node', enable_communication_interface=True)
        self.robot = robot
    
    def on_configure(self, state: State) -> TransitionCallbackReturn:
        """
        Configure state: Setup resources
        """
        self.get_logger().info('Configuring robot...')
        
        # Setup publishers
        self.cmd_pub = self.create_publisher(
            JointState, '/joint_commands', 10
        )
        
        # Setup subscribers
        self.vla_sub = self.create_subscription(
            Image, '/camera/image_raw',
            self.vla_callback, 10
        )
        
        # Setup diagnostics
        from diagnostic_updater import Updater, DiagnosticTask
        self.diagnostics = Updater(self)
        self.diagnostics.add("Robot Status", self.diagnostic_callback)
        
        return TransitionCallbackReturn.SUCCESS
    
    def on_activate(self, state: State) -> TransitionCallbackReturn:
        """
        Activate state: Start operations
        """
        self.get_logger().info('Activating robot...')
        
        # Enable robot
        self.robot.enable()
        
        # Start control loop
        self.create_timer(0.1, self.control_loop)
        
        return TransitionCallbackReturn.SUCCESS
    
    def on_deactivate(self, state: State) -> TransitionCallbackReturn:
        """
        Deactivate state: Stop operations
        """
        self.get_logger().info('Deactivating robot...')
        
        # Stop robot
        self.robot.stop()
        
        return TransitionCallbackReturn.SUCCESS
    
    def diagnostic_callback(self, stat):
        """
        Diagnostics updater
        """
        stat.summary(DiagnosticStatus.OK, "Robot operational")
        
        # Add diagnostic info
        stat.add("Joint positions", str(self.robot.get_joint_positions()))
        stat.add("Battery", "85%")
        stat.add("Temperature", "45¬∞C")
        
        return stat
    
    def vla_callback(self, msg):
        """
        VLA inference and control
        """
        # Image preprocessing
        image = self.bridge_image(msg)
        
        # VLA inference
        action = self.vla_model.predict(image)
        
        # Publish command
        joint_msg = JointState()
        joint_msg.position = action.tolist()
        self.cmd_pub.publish(joint_msg)

# TF2 broadcasting
from tf2_ros import TransformBroadcaster
from geometry_msgs.msg import TransformStamped

class TF2RobotBroadcaster:
    """
    Robot transforms broadcasting
    """
    
    def __init__(self, robot, node):
        self.robot = robot
        self.broadcaster = TransformBroadcaster(node)
    
    def broadcast_transforms(self):
        """
        Broadcast robot transforms
        """
        # Base link ‚Üí World
        t = TransformStamped()
        t.header.stamp = node.get_clock().now().to_msg()
        t.header.frame_id = 'world'
        t.child_frame_id = 'base_link'
        
        position, orientation = self.robot.base.get_world_pose()
        t.transform.translation.x = position[0]
        t.transform.translation.y = position[1]
        t.transform.translation.z = position[2]
        t.transform.rotation.x = orientation[0]
        t.transform.rotation.y = orientation[1]
        t.transform.rotation.z = orientation[2]
        t.transform.rotation.w = orientation[3]
        
        self.broadcaster.sendTransform(t)
        
        # Add other links...
```

**ÏãúÍ∞Ñ: Ï£º 8-10ÏãúÍ∞Ñ**

---

### Week 5-8: Î¨ºÎ•ò ÌôòÍ≤Ω Íµ¨Ï∂ï

#### Ï∞ΩÍ≥† ÌôòÍ≤Ω Î™®Îç∏ÎßÅ
```python
# warehouse_environment.py
from omni.isaac.core import World
from omni.isaac.core.objects import FixedCuboid, DynamicCuboid
from omni.isaac.core.prims import RigidPrim
import numpy as np

class WarehouseEnvironment:
    """
    Î¨ºÎ•ò Ï∞ΩÍ≥† ÌôòÍ≤Ω
    
    Íµ¨ÏÑ±:
    - Î∞îÎã• (50m x 50m)
    - ÏÑ†Î∞ò 5Í∞ú (2m Í∞ÑÍ≤©)
    - ÌåîÎ†àÌä∏ Íµ¨Ïó≠
    - Î∞ïÏä§ (Îã§ÏñëÌïú ÌÅ¨Í∏∞)
    - Ï°∞Î™Ö
    """
    
    def __init__(self, world):
        self.world = world
        self.boxes = []
        
        # Setup environment
        self.setup_floor()
        self.setup_shelves()
        self.setup_pallet_area()
        self.setup_lighting()
    
    def setup_floor(self):
        """
        Î∞îÎã• ÏÑ§Ï†ï
        """
        self.floor = self.world.scene.add(
            FixedCuboid(
                prim_path="/World/Floor",
                position=[0, 0, -0.05],
                scale=[50.0, 50.0, 0.1],
                color=[0.5, 0.5, 0.5]
            )
        )
        
        # ÎßàÏ∞∞ Í≥ÑÏàò ÏÑ§Ï†ï
        from pxr import PhysxSchema
        stage = omni.usd.get_context().get_stage()
        floor_prim = stage.GetPrimAtPath("/World/Floor")
        
        physx_api = PhysxSchema.PhysxRigidBodyAPI.Apply(floor_prim)
        physx_api.CreateLinearDampingAttr(0.1)
        physx_api.CreateAngularDampingAttr(0.1)
    
    def setup_shelves(self):
        """
        ÏÑ†Î∞ò ÏÑ§Ï†ï (5Í∞ú)
        """
        self.shelves = []
        
        for i in range(5):
            x_pos = i * 2.0 - 4.0  # -4, -2, 0, 2, 4
            
            shelf = self.world.scene.add(
                FixedCuboid(
                    prim_path=f"/World/Shelf_{i}",
                    position=[x_pos, 3.0, 1.0],
                    scale=[1.0, 0.3, 2.0],
                    color=[0.6, 0.4, 0.2]
                )
            )
            
            self.shelves.append(shelf)
    
    def setup_pallet_area(self):
        """
        ÌåîÎ†àÌä∏ ÏòÅÏó≠
        """
        # ÌåîÎ†àÌä∏ (1.2m x 1.0m)
        self.pallet = self.world.scene.add(
            RigidPrim(
                prim_path="/World/Pallet",
                position=[5.0, 0, 0.1],
                scale=[1.2, 1.0, 0.2]
            )
        )
        
        # ÌåîÎ†àÌä∏ material
        from omni.isaac.core.materials import PhysicsMaterial
        
        pallet_material = PhysicsMaterial(
            prim_path="/World/Materials/PalletMaterial",
            static_friction=0.8,
            dynamic_friction=0.6,
            restitution=0.1
        )
        
        self.pallet.apply_physics_material(pallet_material)
    
    def setup_lighting(self):
        """
        Ï∞ΩÍ≥† Ï°∞Î™Ö (ÌòïÍ¥ëÎì± ÏãúÎÆ¨Î†àÏù¥ÏÖò)
        """
        from omni.isaac.core.utils.prims import create_prim
        
        # 4Í∞úÏùò Ï≤úÏû• Ï°∞Î™Ö
        for i in range(4):
            x_pos = i * 10.0 - 15.0
            
            light = create_prim(
                prim_path=f"/World/Light_{i}",
                prim_type="RectLight",
                position=[x_pos, 0, 8.0],
                attributes={
                    "intensity": 5000,
                    "width": 5.0,
                    "height": 5.0,
                    "color": (1.0, 1.0, 0.9),  # ÏïΩÍ∞Ñ ÎÖ∏ÎûÄÎπõ
                    "enableColorTemperature": True,
                    "colorTemperature": 5500  # Daylight
                }
            )
    
    def spawn_box(self, size="medium", position=None):
        """
        Î∞ïÏä§ ÏÉùÏÑ±
        
        Args:
            size: "small", "medium", "large"
            position: [x, y, z] or None (random)
        """
        # ÌÅ¨Í∏∞ Ï†ïÏùò
        box_sizes = {
            "small": [0.2, 0.2, 0.2],
            "medium": [0.3, 0.3, 0.3],
            "large": [0.4, 0.4, 0.5]
        }
        
        scale = box_sizes[size]
        
        # ÏúÑÏπò (random if not specified)
        if position is None:
            position = [
                np.random.uniform(-2, 2),
                np.random.uniform(-2, 2),
                1.0
            ]
        
        # ÏÉâÏÉÅ (ÌÅ¨Í∏∞Î≥Ñ)
        colors = {
            "small": [1.0, 0.5, 0.5],  # Îπ®Í∞ï
            "medium": [0.5, 1.0, 0.5],  # Ï¥àÎ°ù
            "large": [0.5, 0.5, 1.0]    # ÌååÎûë
        }
        
        # Î∞ïÏä§ ÏÉùÏÑ±
        box_idx = len(self.boxes)
        box = self.world.scene.add(
            DynamicCuboid(
                prim_path=f"/World/Box_{box_idx}",
                position=position,
                scale=scale,
                color=colors[size],
                mass=1.0 if size == "small" else 2.0 if size == "medium" else 3.0
            )
        )
        
        self.boxes.append({
            'object': box,
            'size': size,
            'prim_path': f"/World/Box_{box_idx}"
        })
        
        return box
    
    def reset(self):
        """
        ÌôòÍ≤Ω Î¶¨ÏÖã
        """
        # Î∞ïÏä§ Ï†úÍ±∞
        for box_info in self.boxes:
            self.world.scene.remove_object(box_info['prim_path'])
        
        self.boxes = []
        
        # ÏÉà Î∞ïÏä§ ÏÉùÏÑ± (ÎûúÎç§)
        num_boxes = np.random.randint(3, 8)
        sizes = np.random.choice(["small", "medium", "large"], num_boxes)
        
        for size in sizes:
            self.spawn_box(size)

# ÏÇ¨Ïö© ÏòàÏãú
world = World()
warehouse = WarehouseEnvironment(world)

# Ï¥àÍ∏∞ Î∞ïÏä§ ÏÉùÏÑ±
warehouse.spawn_box("small", position=[1, 0, 0.5])
warehouse.spawn_box("medium", position=[2, 0, 0.5])
warehouse.spawn_box("large", position=[3, 0, 0.5])

# Simulation
for i in range(1000):
    world.step(render=True)
    
    # Ï£ºÍ∏∞Ï†Å Î¶¨ÏÖã
    if i % 500 == 0 and i > 0:
        warehouse.reset()
```

---

#### Domain Randomization
```python
# domain_randomization.py
import random
import numpy as np

class DomainRandomizer:
    """
    Sim-to-RealÏùÑ ÏúÑÌïú ÌôòÍ≤Ω Îã§ÏñëÌôî
    
    Î™©Ï†Å:
    - SimulationÏùò Îã§ÏñëÏÑ± Ï¶ùÍ∞Ä
    - Real worldÏùò Î≥ÄÎèôÏÑ± ÎåÄÎπÑ
    - RobustÌïú policy ÌïôÏäµ
    """
    
    def __init__(self, world):
        self.world = world
    
    def randomize_environment(self):
        """
        Ï†ÑÏ≤¥ ÌôòÍ≤Ω ÎûúÎç§Ìôî
        """
        self.randomize_physics()
        self.randomize_lighting()
        self.randomize_colors()
        self.randomize_camera()
        self.randomize_objects()
    
    def randomize_physics(self):
        """
        Î¨ºÎ¶¨ ÌååÎùºÎØ∏ÌÑ∞ ÎûúÎç§Ìôî
        """
        # Gravity (¬±5%)
        gravity_z = np.random.uniform(-10.3, -9.3)
        self.world.scene.set_gravity([0, 0, gravity_z])
        
        # Friction (Ï†ÑÏ≤¥ objectÏóê Ï†ÅÏö©)
        friction_multiplier = np.random.uniform(0.7, 1.3)
        
        for obj in self.world.scene.get_all_objects():
            if hasattr(obj, 'get_applied_physics_material'):
                material = obj.get_applied_physics_material()
                if material:
                    # Randomize friction
                    base_friction = 0.5
                    new_friction = base_friction * friction_multiplier
                    material.set_static_friction(new_friction)
                    material.set_dynamic_friction(new_friction * 0.8)
    
    def randomize_lighting(self):
        """
        Ï°∞Î™Ö ÎûúÎç§Ìôî
        
        Î≥ÄÎèô:
        - Í∞ïÎèÑ: ¬±30%
        - ÏÉâÏò®ÎèÑ: 4000K ~ 6500K
        - ÏúÑÏπò: ¬±20cm
        """
        from pxr import UsdLux
        
        stage = omni.usd.get_context().get_stage()
        
        for i in range(4):
            light_path = f"/World/Light_{i}"
            light_prim = stage.GetPrimAtPath(light_path)
            
            if light_prim:
                light = UsdLux.RectLight(light_prim)
                
                # Intensity
                base_intensity = 5000
                intensity = base_intensity * np.random.uniform(0.7, 1.3)
                light.GetIntensityAttr().Set(intensity)
                
                # Color temperature
                temp = np.random.uniform(4000, 6500)
                light.GetColorTemperatureAttr().Set(temp)
                
                # Position noise
                current_pos = light.GetPrim().GetAttribute('xformOp:translate').Get()
                noise = np.random.uniform(-0.2, 0.2, 3)
                new_pos = current_pos + noise
                light.GetPrim().GetAttribute('xformOp:translate').Set(tuple(new_pos))
    
    def randomize_colors(self):
        """
        Í∞ùÏ≤¥ ÏÉâÏÉÅ ÎûúÎç§Ìôî
        """
        for box_info in warehouse.boxes:
            box = box_info['object']
            
            # Random color (HSV spaceÏóêÏÑú)
            hue = random.random()
            saturation = random.uniform(0.5, 1.0)
            value = random.uniform(0.5, 1.0)
            
            # HSV to RGB
            import colorsys
            rgb = colorsys.hsv_to_rgb(hue, saturation, value)
            
            box.set_color(rgb)
    
    def randomize_camera(self):
        """
        Ïπ¥Î©îÎùº ÌååÎùºÎØ∏ÌÑ∞ ÎûúÎç§Ìôî
        
        Î≥ÄÎèô:
        - ÏúÑÏπò: ¬±2cm
        - Í∞ÅÎèÑ: ¬±5ÎèÑ
        - FOV: ¬±5ÎèÑ
        """
        camera_prim_path = "/World/Robot/Camera"
        camera = self.world.scene.get_object(camera_prim_path)
        
        if camera:
            # Position noise
            current_pos, current_rot = camera.get_local_pose()
            pos_noise = np.random.normal(0, 0.02, 3)  # ¬±2cm
            new_pos = current_pos + pos_noise
            
            # Orientation noise
            from scipy.spatial.transform import Rotation
            angle_noise = np.random.uniform(-5, 5, 3)  # ¬±5 degrees
            rot_noise = Rotation.from_euler('xyz', angle_noise, degrees=True)
            current_rot_obj = Rotation.from_quat(current_rot)
            new_rot = (current_rot_obj * rot_noise).as_quat()
            
            camera.set_local_pose(new_pos, new_rot)
    
    def randomize_objects(self):
        """
        Í∞ùÏ≤¥ ÏÜçÏÑ± ÎûúÎç§Ìôî
        """
        for box_info in warehouse.boxes:
            box = box_info['object']
            
            # Mass variation (¬±20%)
            base_mass = box.get_mass()
            new_mass = base_mass * np.random.uniform(0.8, 1.2)
            box.set_mass(new_mass)
            
            # Size variation (¬±5%)
            current_scale = box.get_scale()
            scale_factor = np.random.uniform(0.95, 1.05)
            new_scale = current_scale * scale_factor
            box.set_scale(new_scale)
    
    def apply_texture_randomization(self):
        """
        ÌÖçÏä§Ï≤ò ÎûúÎç§Ìôî (Í≥†Í∏â)
        """
        # Add noise to textures
        # Apply different materials
        pass

# ÏÇ¨Ïö© ÏòàÏãú
randomizer = DomainRandomizer(world)

# Í∞Å ÏóêÌîºÏÜåÎìúÎßàÎã§ ÌôòÍ≤Ω ÎûúÎç§Ìôî
for episode in range(num_episodes):
    # Reset
    warehouse.reset()
    
    # Randomize
    randomizer.randomize_environment()
    
    # Collect data or evaluate
    # ...
```

---

#### Ïπ¥Î©îÎùº ÏÑ§Ï†ï
```python
# camera_setup.py
from omni.isaac.sensor import Camera
import numpy as np

class RobotCamera:
    """
    RGB-D Ïπ¥Î©îÎùº
    
    ÏúÑÏπò: Î°úÎ¥á ÏÉÅÎã® (eye-in-hand ÎòêÎäî fixed)
    """
    
    def __init__(self, world, parent_prim_path):
        self.world = world
        
        # Create camera
        self.camera = Camera(
            prim_path=f"{parent_prim_path}/Camera",
            position=[0, 0, 0.5],  # Î°úÎ¥á Í∏∞Ï§Ä ÏúÑÏπò
            frequency=20,  # Hz
            resolution=(640, 480),
            orientation=[0, 0, 0, 1]
        )
        
        # Add to scene
        self.world.scene.add(self.camera)
        
        # Initialize
        self.camera.initialize()
        
        # Add depth
        self.camera.add_distance_to_image_plane_to_frame()
        
        # Add segmentation (ÏÑ†ÌÉùÏ†Å)
        # self.camera.add_semantic_segmentation_to_frame()
    
    def get_observation(self):
        """
        Ïπ¥Î©îÎùº observation ÌöçÎìù
        
        Returns:
            dict with 'rgb' and 'depth'
        """
        # Get current frame
        frame = self.camera.get_current_frame()
        
        # RGB
        rgb = frame['rgba'][:, :, :3]  # Remove alpha channel
        
        # Depth
        depth = frame['distance_to_image_plane']
        
        # Normalize depth (0-5m ‚Üí 0-1)
        depth = np.clip(depth, 0, 5.0) / 5.0
        
        return {
            'rgb': rgb,
            'depth': depth
        }
    
    def get_camera_intrinsics(self):
        """
        Ïπ¥Î©îÎùº ÎÇ¥Î∂Ä ÌååÎùºÎØ∏ÌÑ∞
        """
        # Get camera parameters
        fov = self.camera.get_horizontal_fov()
        width, height = self.camera.get_resolution()
        
        # Compute focal length
        fx = (width / 2.0) / np.tan(np.radians(fov / 2.0))
        fy = fx  # Assume square pixels
        
        cx = width / 2.0
        cy = height / 2.0
        
        intrinsics = np.array([
            [fx, 0, cx],
            [0, fy, cy],
            [0, 0, 1]
        ])
        
        return intrinsics
    
    def project_3d_to_2d(self, point_3d):
        """
        3D Ï†êÏùÑ Ïù¥ÎØ∏ÏßÄ ÌèâÎ©¥Ïóê Ìà¨ÏòÅ
        
        Args:
            point_3d: [x, y, z] in camera frame
        
        Returns:
            [u, v] in image coordinates
        """
        K = self.get_camera_intrinsics()
        
        # Project
        point_2d_homogeneous = K @ point_3d
        u = point_2d_homogeneous[0] / point_2d_homogeneous[2]
        v = point_2d_homogeneous[1] / point_2d_homogeneous[2]
        
        return np.array([u, v])

# Multiple cameras
class MultiCameraSetup:
    """
    Ïó¨Îü¨ Ïπ¥Î©îÎùº (Îã§ÏñëÌïú viewpoint)
    """
    
    def __init__(self, world, robot_prim_path):
        self.cameras = {}
        
        # Wrist camera (eye-in-hand)
        self.cameras['wrist'] = RobotCamera(
            world,
            f"{robot_prim_path}/wrist"
        )
        
        # Front camera (fixed)
        self.cameras['front'] = RobotCamera(
            world,
            f"{robot_prim_path}/base"
        )
        
        # Top-down camera (bird's eye view)
        self.cameras['top'] = RobotCamera(
            world,
            "/World/TopCamera"
        )
    
    def get_all_observations(self):
        """
        Î™®Îì† Ïπ¥Î©îÎùºÏóêÏÑú observation
        """
        observations = {}
        
        for name, camera in self.cameras.items():
            observations[name] = camera.get_observation()
        
        return observations
```

**ÏãúÍ∞Ñ: Ï£º 8-10ÏãúÍ∞Ñ**

---

## Month 9: Action & Observation Space ÏÑ§Í≥Ñ

### Week 1: Action Space ÏÑ§Í≥Ñ ‚ö†Ô∏è Îß§Ïö∞ Ï§ëÏöî!

#### ÏÑ§Í≥Ñ Í≥†Î†§ÏÇ¨Ìï≠
```python
# action_space.py

class ActionSpace:
    """
    VLAÏùò Ï∂úÎ†•ÏùÑ Ïñ¥ÎñªÍ≤å Ï†ïÏùòÌï† Í≤ÉÏù∏Í∞Ä?
    
    ÌïµÏã¨ Í≤∞Ï†ïÏÇ¨Ìï≠:
    1. Control Space (Joint vs Cartesian)
    2. Control Mode (Position vs Velocity vs Torque)
    3. Absolute vs Delta
    4. Normalization
    5. Gripper control
    """
    
    def __init__(self, robot, control_type='delta_joint'):
        self.robot = robot
        self.control_type = control_type
        
        # Joint limits
        self.joint_min = np.array([-3.14, -3.14, -3.14, -3.14, -3.14, -3.14, 0])
        self.joint_max = np.array([3.14, 3.14, 3.14, 3.14, 3.14, 3.14, 1])
        
        # Delta limits (ÏûëÍ≤å!)
        self.delta_max = np.array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.2])
        
        # Velocity limits
        self.velocity_max = np.array([2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0])

# Option 1: Absolute Joint Position
"""
Ïû•Ï†ê:
- ÏßÅÏ†ëÏ†ÅÏù∏ Ï†úÏñ¥
- Singularity ÏóÜÏùå
- Îπ†Î•∏ Ïã§Ìñâ

Îã®Ï†ê:
- ÏßÅÍ¥ÄÏ†ÅÏù¥ÏßÄ ÏïäÏùå
- Task space reasoning Ïñ¥Î†§ÏõÄ

ÏÇ¨Ïö© ÏãúÍ∏∞:
- Ï†ïÎ∞ÄÌïú Ï†úÏñ¥ ÌïÑÏöî
- ÏßßÏùÄ horizon task
"""
class AbsoluteJointSpace(ActionSpace):
    def __init__(self, robot):
        super().__init__(robot, 'absolute_joint')
        self.action_dim = 7  # 6-DOF arm + gripper
    
    def normalize(self, action):
        """
        [joint_min, joint_max] ‚Üí [-1, 1]
        """
        normalized = 2 * (action - self.joint_min) / \
                    (self.joint_max - self.joint_min) - 1
        return normalized
    
    def denormalize(self, normalized_action):
        """
        [-1, 1] ‚Üí [joint_min, joint_max]
        """
        action = (normalized_action + 1) / 2 * \
                (self.joint_max - self.joint_min) + self.joint_min
        return action
    
    def apply(self, normalized_action):
        """
        Apply action to robot
        """
        action = self.denormalize(normalized_action)
        
        # Safety check
        action = np.clip(action, self.joint_min, self.joint_max)
        
        # Apply
        self.robot.set_joint_positions(action)

# Option 2: Delta Joint (Ï∂îÏ≤ú!)
"""
Ïû•Ï†ê:
- ÌïôÏäµ ÏïàÏ†ïÏ†Å
- ÏóêÎü¨ ÎàÑÏ†Å Î∞©ÏßÄ
- Smooth control
- Safe (ÏûëÏùÄ step)

Îã®Ï†ê:
- Long-horizon planning Ïñ¥Î†§ÏõÄ

ÏÇ¨Ïö© ÏãúÍ∏∞:
- ÎåÄÎ∂ÄÎ∂ÑÏùò VLA
- BC ÌïôÏäµ
"""
class DeltaJointSpace(ActionSpace):
    def __init__(self, robot):
        super().__init__(robot, 'delta_joint')
        self.action_dim = 7
    
    def normalize(self, delta_action):
        """
        [-delta_max, delta_max] ‚Üí [-1, 1]
        """
        normalized = delta_action / self.delta_max
        normalized = np.clip(normalized, -1, 1)
        return normalized
    
    def denormalize(self, normalized_action):
        """
        [-1, 1] ‚Üí [-delta_max, delta_max]
        """
        delta = normalized_action * self.delta_max
        return delta
    
    def apply(self, normalized_action):
        """
        Apply delta to current position
        """
        delta = self.denormalize(normalized_action)
        
        # Current position
        current = self.robot.get_joint_positions()
        
        # Target position
        target = current + delta
        
        # Safety: Joint limits
        target = np.clip(target, self.joint_min, self.joint_max)
        
        # Apply
        self.robot.set_joint_positions(target)

# Option 3: Cartesian Space
"""
Ïû•Ï†ê:
- ÏßÅÍ¥ÄÏ†Å
- Task Ï§ëÏã¨
- Ïâ¨Ïö¥ demonstration

Îã®Ï†ê:
- IK ÌïÑÏöî (Ï∂îÍ∞Ä Ïò§Ï∞®)
- Singularity Í∞ÄÎä•
- ÎäêÎ¶º

ÏÇ¨Ïö© ÏãúÍ∏∞:
- Teleoperation
- Sparse reward task
"""
class CartesianSpace(ActionSpace):
    def __init__(self, robot):
        super().__init__(robot, 'cartesian')
        self.action_dim = 7  # [x, y, z, qx, qy, qz, qw]
        
        # Workspace limits
        self.workspace_min = np.array([0.2, -0.5, 0.0])
        self.workspace_max = np.array([0.8, 0.5, 1.0])
    
    def apply(self, normalized_action):
        """
        Apply Cartesian action
        """
        # Denormalize position
        position = normalized_action[:3]
        position = (position + 1) / 2 * \
                  (self.workspace_max - self.workspace_min) + \
                  self.workspace_min
        
        # Quaternion (already normalized)
        orientation = normalized_action[3:]
        
        # IK
        joint_positions = self.inverse_kinematics(position, orientation)
        
        if joint_positions is not None:
            self.robot.set_joint_positions(joint_positions)
    
    def inverse_kinematics(self, position, orientation):
        """
        IK solver
        """
        from omni.isaac.manipulators import IKSolver
        
        ik_solver = IKSolver(self.robot)
        joint_positions = ik_solver.solve(position, orientation)
        
        return joint_positions
```

---

#### Action Chunking (RT-1 Î∞©Ïãù)
```python
# action_chunking.py

class ActionChunking:
    """
    Ìïú Î≤àÏóê Ïó¨Îü¨ timestepÏùò action ÏòàÏ∏°
    
    Ïû•Ï†ê:
    - Temporal consistency
    - Smoother trajectories
    - Less myopic (Îçî Î®º ÎØ∏Îûò Í≥†Î†§)
    - Training stability
    
    Îã®Ï†ê:
    - Ïã§ÏãúÍ∞ÑÏÑ± ÏïΩÍ∞Ñ Ï†ÄÌïò
    - Î©îÎ™®Î¶¨ Ï¶ùÍ∞Ä
    """
    
    def __init__(self, model, chunk_size=10, execute_ratio=0.5):
        self.model = model
        self.chunk_size = chunk_size
        self.execute_steps = int(chunk_size * execute_ratio)
        
        self.action_buffer = []
    
    def predict_chunk(self, observation):
        """
        ModelÏù¥ chunk_sizeÎßåÌÅºÏùò action ÏòàÏ∏°
        
        Args:
            observation: Current observation
        
        Returns:
            action_chunk: (chunk_size, action_dim)
        """
        # Model forward
        with torch.no_grad():
            action_chunk = self.model.predict_sequence(
                observation,
                sequence_length=self.chunk_size
            )
        
        return action_chunk
    
    def get_next_action(self, observation):
        """
        Îã§Ïùå action Î∞òÌôò
        
        Logic:
        1. BufferÍ∞Ä ÎπÑÏóàÏúºÎ©¥ new chunk ÏòàÏ∏°
        2. BufferÏóêÏÑú action ÌïòÎÇò pop
        3. Execute_stepsÎßåÌÅº Ïã§ÌñâÌñàÏúºÎ©¥ new chunk
        """
        # Buffer empty or need refresh?
        if len(self.action_buffer) == 0:
            # Predict new chunk
            chunk = self.predict_chunk(observation)
            self.action_buffer = list(chunk)
            self.executed_count = 0
        
        # Pop action
        action = self.action_buffer.pop(0)
        self.executed_count += 1
        
        # Re-predict if executed enough
        if self.executed_count >= self.execute_steps:
            self.action_buffer = []
        
        return action

# Model with chunking
class VLAWithChunking(nn.Module):
    """
    Action chunkingÏùÑ ÏßÄÏõêÌïòÎäî VLA
    """
    
    def __init__(self, vision_encoder, chunk_size=10):
        super().__init__()
        
        self.vision_encoder = vision_encoder
        self.chunk_size = chunk_size
        
        # Temporal decoder
        self.temporal_decoder = nn.LSTM(
            input_size=768,  # Vision feature dim
            hidden_size=512,
            num_layers=2,
            batch_first=True
        )
        
        # Action head
        self.action_head = nn.Linear(512, 7)  # 7-DOF action
    
    def forward(self, observation):
        """
        Single observation ‚Üí action chunk
        
        Args:
            observation: (B, 3, H, W)
        
        Returns:
            actions: (B, chunk_size, 7)
        """
        # Vision encoding
        vision_features = self.vision_encoder(observation)  # (B, 768)
        
        # Repeat for sequence
        vision_seq = vision_features.unsqueeze(1).repeat(
            1, self.chunk_size, 1
        )  # (B, chunk_size, 768)
        
        # Temporal decoding
        lstm_out, _ = self.temporal_decoder(vision_seq)  # (B, chunk_size, 512)
        
        # Action prediction
        actions = self.action_head(lstm_out)  # (B, chunk_size, 7)
        
        return actions
    
    def predict_sequence(self, observation, sequence_length=None):
        """
        Inference mode
        """
        if sequence_length is None:
            sequence_length = self.chunk_size
        
        self.eval()
        with torch.no_grad():
            # Adjust chunk size temporarily
            original_chunk = self.chunk_size
            self.chunk_size = sequence_length
            
            actions = self.forward(observation)
            
            self.chunk_size = original_chunk
        
        return actions[0]  # Remove batch dimension

# Training with chunking
def train_with_chunking():
    """
    Action chunking ÌïôÏäµ
    
    Data format:
    - observation: (B, 3, H, W)
    - actions: (B, chunk_size, 7)
    """
    model = VLAWithChunking(vision_encoder, chunk_size=10)
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
    criterion = nn.MSELoss()
    
    for epoch in range(num_epochs):
        for obs, action_chunk in dataloader:
            # Forward
            pred_actions = model(obs)
            
            # Loss (Î™®Îì† timestep)
            loss = criterion(pred_actions, action_chunk)
            
            # Backward
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
        
        print(f"Epoch {epoch+1}, Loss: {loss.item():.4f}")
```

---

#### Ïã§Ìóò Í∞ÄÏù¥Îìú
```python
# Ïñ¥Îñ§ action spaceÍ∞Ä Ï¢ãÏùÄÍ∞Ä?

experiments = {
    'exp1_absolute': {
        'space': AbsoluteJointSpace,
        'expected': 'Baseline, potentially unstable'
    },
    'exp2_delta': {
        'space': DeltaJointSpace,
        'expected': 'Stable, smooth, recommended'
    },
    'exp3_delta_chunking': {
        'space': DeltaJointSpace,
        'chunking': ActionChunking(chunk_size=10),
        'expected': 'Best performance'
    },
    'exp4_cartesian': {
        'space': CartesianSpace,
        'expected': 'Intuitive but slower'
    }
}

def compare_action_spaces():
    """
    Action space ÎπÑÍµê Ïã§Ìóò
    """
    results = {}
    
    for exp_name, config in experiments.items():
        print(f"\n{'='*60}")
        print(f"Experiment: {exp_name}")
        print(f"{'='*60}")
        
        # Setup
        action_space = config['space'](robot)
        
        # Train
        model = train_vla(action_space)
        
        # Evaluate
        metrics = evaluate_model(model, action_space)
        
        results[exp_name] = metrics
        
        print(f"Results:")
        print(f"  Success Rate: {metrics['success_rate']:.2%}")
        print(f"  Smoothness: {metrics['smoothness']:.4f}")
        print(f"  Avg Time: {metrics['avg_time']:.2f}s")
    
    # Plot comparison
    plot_comparison(results)
    
    return results

# ÌèâÍ∞Ä Í∏∞Ï§Ä:
"""
1. Success Rate (Í∞ÄÏû• Ï§ëÏöî!)
2. Trajectory Smoothness (jerk)
3. Learning Stability (loss curve)
4. Inference Time
5. Sim-to-Real Gap (ÎÇòÏ§ëÏóê)
"""
```

**ÏãúÍ∞Ñ: Ï£º 8-10ÏãúÍ∞Ñ**

---

### Week 2: Observation Space ÏÑ§Í≥Ñ

#### Observation Íµ¨ÏÑ±
```python
# observation_space.py

class ObservationSpace:
    """
    VLA ÏûÖÎ†•ÏùÑ Ïñ¥ÎñªÍ≤å Íµ¨ÏÑ±Ìï† Í≤ÉÏù∏Í∞Ä?
    
    Í∞ÄÎä•Ìïú modality:
    1. Vision: RGB, Depth, Semantic
    2. Proprioception: Joint state, EE pose
    3. Language: Task instruction
    4. History: Past observations
    5. Goal: Target state
    """
    
    def __init__(self, config):
        self.use_rgb = config.get('use_rgb', True)
        self.use_depth = config.get('use_depth', False)
        self.use_proprio = config.get('use_proprio', True)
        self.use_language = config.get('use_language', False)
        self.history_length = config.get('history_length', 1)
        
        # History buffer
        from collections import deque
        self.history_buffer = deque(maxlen=self.history_length)
    
    def get_observation(self, camera, robot, instruction=None):
        """
        ÌòÑÏû¨ observation ÏàòÏßë
        
        Returns:
            dict with various modalities
        """
        obs = {}
        
        # Vision
        if self.use_rgb:
            rgb = camera.get_rgb()  # (H, W, 3)
            obs['rgb'] = self.preprocess_image(rgb)
        
        if self.use_depth:
            depth = camera.get_depth()  # (H, W, 1)
            obs['depth'] = self.preprocess_depth(depth)
        
        # Proprioception
        if self.use_proprio:
            obs['joint_pos'] = robot.get_joint_positions()  # (7,)
            obs['joint_vel'] = robot.get_joint_velocities()  # (7,)
            obs['ee_pose'] = robot.get_end_effector_pose()  # (7,)
            obs['gripper_state'] = robot.get_gripper_state()  # (1,)
        
        # Language
        if self.use_language and instruction:
            obs['instruction'] = self.encode_instruction(instruction)
        
        # History
        if self.history_length > 1:
            self.history_buffer.append(obs.copy())
            obs['history'] = list(self.history_buffer)
        
        return obs
    
    def preprocess_image(self, image):
        """
        Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨
        
        Steps:
        1. Resize to 224x224
        2. Normalize [0, 255] ‚Üí [0, 1]
        3. ImageNet normalization
        4. Channels first (C, H, W)
        """
        import cv2
        
        # Resize
        image = cv2.resize(image, (224, 224))
        
        # Normalize
        image = image.astype(np.float32) / 255.0
        
        # ImageNet normalization
        mean = np.array([0.485, 0.456, 0.406])
        std = np.array([0.229, 0.224, 0.225])
        image = (image - mean) / std
        
        # Channels first
        image = np.transpose(image, (2, 0, 1))
        
        return image
    
    def preprocess_depth(self, depth):
        """
        Depth Ï†ÑÏ≤òÎ¶¨
        
        Steps:
        1. Clip far values (> 5m)
        2. Normalize to [0, 1]
        3. Resize if needed
        """
        # Clip
        depth = np.clip(depth, 0, 5.0)
        
        # Normalize
        depth = depth / 5.0
        
        # Add channel dimension if needed
        if len(depth.shape) == 2:
            depth = depth[..., np.newaxis]
        
        return depth
    
    def encode_instruction(self, instruction):
        """
        Language instruction encoding
        
        Methods:
        1. BERT tokenizer
        2. CLIP text encoder
        3. Simple word embedding
        """
        from transformers import AutoTokenizer
        
        tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
        
        tokens = tokenizer(
            instruction,
            padding='max_length',
            max_length=20,
            truncation=True,
            return_tensors='np'
        )
        
        return tokens['input_ids']

# Multi-modal Fusion
class MultiModalObservation(nn.Module):
    """
    Îã§ÏñëÌïú observationÏùÑ Ïñ¥ÎñªÍ≤å Í≤∞Ìï©Ìï†Íπå?
    
    Architecture:
    1. Separate encoders for each modality
    2. Fusion layer
    3. Joint representation
    """
    
    def __init__(self, config):
        super().__init__()
        
        self.use_rgb = config['use_rgb']
        self.use_depth = config['use_depth']
        self.use_proprio = config['use_proprio']
        self.use_language = config['use_language']
        
        # Vision encoder (RGB)
        if self.use_rgb:
            from transformers import ViTModel
            self.rgb_encoder = ViTModel.from_pretrained(
                'google/vit-base-patch16-224'
            )
            rgb_dim = 768
        else:
            rgb_dim = 0
        
        # Depth encoder
        if self.use_depth:
            self.depth_encoder = nn.Sequential(
                nn.Conv2d(1, 32, 3, 2, 1),
                nn.ReLU(),
                nn.Conv2d(32, 64, 3, 2, 1),
                nn.ReLU(),
                nn.AdaptiveAvgPool2d((1, 1)),
                nn.Flatten(),
                nn.Linear(64, 256)
            )
            depth_dim = 256
        else:
            depth_dim = 0
        
        # Proprioception encoder
        if self.use_proprio:
            # 7 pos + 7 vel + 7 ee_pose + 1 gripper = 22
            self.proprio_encoder = nn.Sequential(
                nn.Linear(22, 128),
                nn.ReLU(),
                nn.Linear(128, 256)
            )
            proprio_dim = 256
        else:
            proprio_dim = 0
        
        # Language encoder
        if self.use_language:
            from transformers import AutoModel
            self.language_encoder = AutoModel.from_pretrained(
                "bert-base-uncased"
            )
            lang_dim = 768
        else:
            lang_dim = 0
        
        # Fusion
        total_dim = rgb_dim + depth_dim + proprio_dim + lang_dim
        self.fusion = nn.Sequential(
            nn.Linear(total_dim, 512),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(512, 512)
        )
    
    def forward(self, obs):
        """
        Encode and fuse all modalities
        
        Args:
            obs: dict with various keys
        
        Returns:
            fused_features: (B, 512)
        """
        features = []
        
        # RGB
        if self.use_rgb and 'rgb' in obs:
            rgb_feat = self.rgb_encoder(obs['rgb']).last_hidden_state[:, 0]
            features.append(rgb_feat)
        
        # Depth
        if self.use_depth and 'depth' in obs:
            depth_feat = self.depth_encoder(obs['depth'])
            features.append(depth_feat)
        
        # Proprioception
        if self.use_proprio:
            proprio = torch.cat([
                obs['joint_pos'],
                obs['joint_vel'],
                obs['ee_pose'],
                obs['gripper_state']
            ], dim=-1)
            proprio_feat = self.proprio_encoder(proprio)
            features.append(proprio_feat)
        
        # Language
        if self.use_language and 'instruction' in obs:
            lang_feat = self.language_encoder(
                obs['instruction']
            ).last_hidden_state[:, 0]
            features.append(lang_feat)
        
        # Concatenate
        combined = torch.cat(features, dim=-1)
        
        # Fuse
        fused = self.fusion(combined)
        
        return fused
```

---

#### Ablation Study
```python
# observation_ablation.py

def observation_ablation_study():
    """
    Observation modality ablation
    
    Î™©Ï†Å: Í∞Å modalityÏùò Í∏∞Ïó¨ÎèÑ Ï∏°Ï†ï
    """
    
    configs = {
        'rgb_only': {
            'use_rgb': True,
            'use_depth': False,
            'use_proprio': False,
            'use_language': False
        },
        'rgb_proprio': {
            'use_rgb': True,
            'use_depth': False,
            'use_proprio': True,
            'use_language': False
        },
        'rgb_depth': {
            'use_rgb': True,
            'use_depth': True,
            'use_proprio': False,
            'use_language': False
        },
        'rgb_depth_proprio': {
            'use_rgb': True,
            'use_depth': True,
            'use_proprio': True,
            'use_language': False
        },
        'full': {
            'use_rgb': True,
            'use_depth': True,
            'use_proprio': True,
            'use_language': True
        }
    }
    
    results = {}
    
    for name, config in configs.items():
        print(f"\n{'='*60}")
        print(f"Configuration: {name}")
        print(f"{'='*60}")
        
        # Train model
        model = train_vla_with_config(config)
        
        # Evaluate
        metrics = evaluate_model(model)
        
        results[name] = metrics
        
        print(f"Success Rate: {metrics['success_rate']:.2%}")
        print(f"Training Time: {metrics['train_time']:.1f}s")
        print(f"Inference Time: {metrics['inference_time']:.3f}s")
    
    # Analysis
    print("\n" + "="*60)
    print("ABLATION ANALYSIS")
    print("="*60)
    
    # Best configuration
    best_config = max(results.items(), key=lambda x: x[1]['success_rate'])
    print(f"Best: {best_config[0]} ({best_config[1]['success_rate']:.2%})")
    
    # Contribution of each modality
    baseline = results['rgb_only']['success_rate']
    
    print(f"\nContributions:")
    print(f"  Proprio: +{results['rgb_proprio']['success_rate'] - baseline:.1%}")
    print(f"  Depth: +{results['rgb_depth']['success_rate'] - baseline:.1%}")
    
    return results

# ÏùºÎ∞òÏ†ÅÏù∏ Í≤∞Í≥º:
"""
RGB only: 40-50%
RGB + Proprio: 60-70% (ÌÅ∞ Ìñ•ÏÉÅ!)
RGB + Depth: 50-60%
RGB + Depth + Proprio: 70-80% (Best balance)
Full (with Language): 75-85% (task dependent)

Recommendation:
- ÎåÄÎ∂ÄÎ∂Ñ task: RGB + Proprio
- Depth ÌïÑÏöîÌïú Í≤ΩÏö∞: 3D reasoning, occlusion
- Language: Multi-task, zero-shot generalization
"""
```

**ÏãúÍ∞Ñ: Ï£º 8-10ÏãúÍ∞Ñ**

---

## Month 10: Ï≤´ Î¨ºÎ•ò VLA Í∞úÎ∞ú

### Week 1-2: Îç∞Ïù¥ÌÑ∞ ÏàòÏßë & ÌíàÏßà Í¥ÄÎ¶¨

#### Teleoperation ÏãúÏä§ÌÖú
```python
# teleoperation.py
import numpy as np
from pynput import keyboard, mouse

class TeleoperationSystem:
    """
    ÏÇ¨ÎûåÏù¥ Î°úÎ¥áÏùÑ Ï†úÏñ¥ÌïòÎ©∞ demonstration ÏàòÏßë
    
    ÏûÖÎ†• Î∞©Î≤ï:
    1. Keyboard (Í∞ÑÎã®, Î∂ÄÏ†ïÌôï)
    2. SpaceMouse (3D input, Ï∂îÏ≤ú!)
    3. VR Controller (Í∞ÄÏû• ÏßÅÍ¥ÄÏ†Å)
    """
    
    def __init__(self, robot, camera):
        self.robot = robot
        self.camera = camera
        
        # Recording state
        self.recording = False
        self.current_episode = []
        self.episodes = []
        
        # Control state
        self.current_velocity = np.zeros(7)
        
        # Setup input device
        self.setup_keyboard_control()
    
    def setup_keyboard_control(self):
        """
        ÌÇ§Î≥¥Îìú Ï†úÏñ¥ ÏÑ§Ï†ï
        
        ÌÇ§ Îß§Ìïë:
        - W/S: Joint 1 +/-
        - A/D: Joint 2 +/-
        - Q/E: Joint 3 +/-
        - ...
        - Space: Gripper toggle
        - R: Start recording
        - T: Stop recording
        """
        self.key_mapping = {
            'w': (0, 0.5),
            's': (0, -0.5),
            'a': (1, 0.5),
            'd': (1, -0.5),
            'q': (2, 0.5),
            'e': (2, -0.5),
            # ... more keys
        }
        
        self.listener = keyboard.Listener(
            on_press=self.on_press,
            on_release=self.on_release
        )
        self.listener.start()
    
    def on_press(self, key):
        """
        Key press handler
        """
        try:
            char = key.char
            
            # Control joints
            if char in self.key_mapping:
                joint_idx, velocity = self.key_mapping[char]
                self.current_velocity[joint_idx] = velocity
            
            # Recording control
            elif char == 'r':
                self.start_recording()
            elif char == 't':
                self.stop_recording()
            
            # Gripper
            elif char == ' ':
                self.toggle_gripper()
        
        except AttributeError:
            pass
    
    def on_release(self, key):
        """
        Key release handler
        """
        # Stop movement
        self.current_velocity = np.zeros(7)
        
        if key == keyboard.Key.esc:
            return False
    
    def start_recording(self):
        """
        Start recording episode
        """
        self.recording = True
        self.current_episode = []
        print("üî¥ Recording started")
    
    def stop_recording(self):
        """
        Stop recording episode
        """
        if self.recording and len(self.current_episode) > 10:
            self.episodes.append(self.current_episode.copy())
            print(f"‚úÖ Episode {len(self.episodes)} saved ({len(self.current_episode)} frames)")
        else:
            print("‚ùå Episode too short, discarded")
        
        self.recording = False
        self.current_episode = []
    
    def step(self):
        """
        Single control step
        
        Call this in simulation loop
        """
        # Apply control
        self.robot.apply_joint_velocities(self.current_velocity)
        
        # Record if active
        if self.recording:
            obs = self.get_observation()
            action = self.current_velocity.copy()
            
            self.current_episode.append({
                'observation': obs,
                'action': action,
                'timestamp': time.time()
            })
    
    def get_observation(self):
        """
        Get current observation
        """
        return {
            'rgb': self.camera.get_rgb(),
            'depth': self.camera.get_depth(),
            'joint_pos': self.robot.get_joint_positions(),
            'joint_vel': self.robot.get_joint_velocities(),
            'gripper': self.robot.get_gripper_state()
        }
    
    def save_demonstrations(self, filename='demonstrations.pkl'):
        """
        Save collected demonstrations
        """
        import pickle
        
        with open(filename, 'wb') as f:
            pickle.dump(self.episodes, f)
        
        print(f"üíæ Saved {len(self.episodes)} episodes to {filename}")
    
    def toggle_gripper(self):
        """
        Toggle gripper state
        """
        current = self.robot.get_gripper_state()
        if current > 0.5:
            self.robot.close_gripper()
        else:
            self.robot.open_gripper()

# ÏÇ¨Ïö© ÏòàÏãú
teleop = TeleoperationSystem(robot, camera)

print("""
=== Teleoperation Controls ===
W/S: Joint 1
A/D: Joint 2
Q/E: Joint 3
...
Space: Toggle gripper
R: Start recording
T: Stop recording
ESC: Exit
==============================
""")

# Simulation loop
while simulation_app.is_running():
    teleop.step()
    world.step(render=True)
```

---

#### Îç∞Ïù¥ÌÑ∞ ÌíàÏßà Í¥ÄÎ¶¨
```python
# data_quality.py

class DataQualityChecker:
    """
    ÏàòÏßëÌïú Îç∞Ïù¥ÌÑ∞ Í≤ÄÏ¶ù
    
    Ï≤¥ÌÅ¨ Ìï≠Î™©:
    1. Episode length
    2. Action variance
    3. Success/failure
    4. Image quality
    5. Trajectory smoothness
    """
    
    def __init__(self):
        self.quality_thresholds = {
            'min_length': 20,
            'max_length': 500,
            'min_action_std': 0.01,
            'min_brightness': 10,
            'max_jerk': 5.0
        }
    
    def check_episode(self, episode, success=True):
        """
        Single episode Í≤ÄÏ¶ù
        
        Returns:
            is_good: bool
            issues: list of issue strings
        """
        issues = []
        
        # 1. Length check
        length = len(episode)
        if length < self.quality_thresholds['min_length']:
            issues.append(f"Too short ({length} < {self.quality_thresholds['min_length']})")
        
        if length > self.quality_thresholds['max_length']:
            issues.append(f"Too long ({length} > {self.quality_thresholds['max_length']})")
        
        # 2. Action variance
        actions = np.array([step['action'] for step in episode])
        action_std = np.std(actions, axis=0).mean()
        
        if action_std < self.quality_thresholds['min_action_std']:
            issues.append(f"Static actions (std={action_std:.4f})")
        
        # 3. Success check
        if not success:
            # Ïã§Ìå® ÏóêÌîºÏÜåÎìúÎèÑ ÏùºÎ∂Ä Ìè¨Ìï® (10-15%)
            if np.random.random() > 0.15:
                issues.append("Failed episode")
        
        # 4. Image quality
        first_obs = episode[0]['observation']
        image = first_obs['rgb']
        
        brightness = np.mean(image)
        if brightness < self.quality_thresholds['min_brightness']:
            issues.append(f"Too dark (brightness={brightness:.1f})")
        
        contrast = np.std(image)
        if contrast < 5:
            issues.append(f"Low contrast (std={contrast:.1f})")
        
        # 5. Smoothness (jerk)
        velocities = np.diff(actions, axis=0)
        jerks = np.diff(velocities, axis=0)
        max_jerk = np.max(np.abs(jerks))
        
        if max_jerk > self.quality_thresholds['max_jerk']:
            issues.append(f"Jerky movements (max_jerk={max_jerk:.2f})")
        
        is_good = len(issues) == 0
        
        return is_good, issues
    
    def clean_dataset(self, episodes):
        """
        Dataset Ï†ïÏ†ú
        
        Returns:
            clean_episodes: list
            statistics: dict
        """
        clean_episodes = []
        
        statistics = {
            'total': len(episodes),
            'removed_short': 0,
            'removed_long': 0,
            'removed_static': 0,
            'removed_failed': 0,
            'removed_quality': 0,
            'removed_jerky': 0,
            'kept': 0
        }
        
        for i, episode in enumerate(episodes):
            success = episode.get('success', True)
            is_good, issues = self.check_episode(episode['data'], success)
            
            if is_good:
                clean_episodes.append(episode)
                statistics['kept'] += 1
            else:
                # Update statistics
                for issue in issues:
                    if 'short' in issue.lower():
                        statistics['removed_short'] += 1
                    elif 'long' in issue.lower():
                        statistics['removed_long'] += 1
                    elif 'static' in issue.lower():
                        statistics['removed_static'] += 1
                    elif 'failed' in issue.lower():
                        statistics['removed_failed'] += 1
                    elif 'jerky' in issue.lower():
                        statistics['removed_jerky'] += 1
                    else:
                        statistics['removed_quality'] += 1
                
                print(f"Episode {i+1} removed: {', '.join(issues)}")
        
        # Print report
        print("\n" + "="*60)
        print("DATA CLEANING REPORT")
        print("="*60)
        for key, val in statistics.items():
            percentage = (val / statistics['total'] * 100) if statistics['total'] > 0 else 0
            print(f"{key:20s}: {val:4d} ({percentage:5.1f}%)")
        print("="*60)
        
        return clean_episodes, statistics
    
    def visualize_quality(self, episodes):
        """
        Îç∞Ïù¥ÌÑ∞ ÌíàÏßà ÏãúÍ∞ÅÌôî
        """
        import matplotlib.pyplot as plt
        
        # Episode lengths
        lengths = [len(ep['data']) for ep in episodes]
        
        # Action statistics
        all_actions = []
        for ep in episodes:
            actions = [step['action'] for step in ep['data']]
            all_actions.extend(actions)
        all_actions = np.array(all_actions)
        
        # Plot
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        
        # Episode length distribution
        axes[0, 0].hist(lengths, bins=30)
        axes[0, 0].set_title('Episode Length Distribution')
        axes[0, 0].set_xlabel('Length (frames)')
        axes[0, 0].set_ylabel('Count')
        
        # Action distribution
        for i in range(min(7, all_actions.shape[1])):
            axes[0, 1].hist(all_actions[:, i], bins=50, alpha=0.5, label=f'Joint {i+1}')
        axes[0, 1].set_title('Action Distribution')
        axes[0, 1].set_xlabel('Action value')
        axes[0, 1].legend()
        
        # Action correlation
        correlation = np.corrcoef(all_actions.T)
        im = axes[1, 0].imshow(correlation, cmap='coolwarm', vmin=-1, vmax=1)
        axes[1, 0].set_title('Action Correlation')
        plt.colorbar(im, ax=axes[1, 0])
        
        # Success rate over time
        success_rate = []
        window = 10
        for i in range(0, len(episodes), window):
            batch = episodes[i:i+window]
            rate = sum(ep.get('success', True) for ep in batch) / len(batch)
            success_rate.append(rate)
        
        axes[1, 1].plot(success_rate)
        axes[1, 1].set_title('Success Rate Over Collection')
        axes[1, 1].set_xlabel(f'Batch (window={window})')
        axes[1, 1].set_ylabel('Success Rate')
        axes[1, 1].set_ylim([0, 1])
        
        plt.tight_layout()
        plt.savefig('data_quality_report.png')
        plt.show()
```

---

#### Data Augmentation
```python
# data_augmentation.py

class RobotDataAugmentation:
    """
    Ïù¥ÎØ∏ÏßÄ + Action ÎèôÏãú augmentation
    
    Ï£ºÏùò: Ïù¥ÎØ∏ÏßÄÎßå augmentÌïòÎ©¥ Ïïà Îê®!
           ActionÎèÑ Í∞ôÏù¥ Î≥ÄÌôòÌï¥Ïïº consistency Ïú†ÏßÄ
    """
    
    def __init__(self, config):
        self.config = config
        
        # Augmentation probabilities
        self.p_flip = config.get('p_flip', 0.3)
        self.p_rotate = config.get('p_rotate', 0.2)
        self.p_brightness = config.get('p_brightness', 0.3)
        self.p_noise = config.get('p_noise', 0.2)
        self.p_color_jitter = config.get('p_color_jitter', 0.3)
    
    def augment(self, observation, action):
        """
        Augment observation and action together
        
        Args:
            observation: dict with 'rgb', 'depth', etc.
            action: numpy array (7,)
        
        Returns:
            aug_observation: augmented observation
            aug_action: augmented action
        """
        # Copy to avoid in-place modification
        obs = observation.copy()
        act = action.copy()
        
        # 1. Horizontal flip (Ï°∞Ïã¨! actionÎèÑ Î≥ÄÌôò)
        if np.random.random() < self.p_flip:
            obs, act = self.horizontal_flip(obs, act)
        
        # 2. Small rotation (Ï°∞Ïã¨! actionÎèÑ Î≥ÄÌôò)
        if np.random.random() < self.p_rotate:
            angle = np.random.uniform(-5, 5)
            obs, act = self.rotate(obs, act, angle)
        
        # 3. Brightness (action Î∂àÎ≥Ä)
        if np.random.random() < self.p_brightness:
            obs = self.adjust_brightness(obs)
        
        # 4. Gaussian noise (action Î∂àÎ≥Ä)
        if np.random.random() < self.p_noise:
            obs = self.add_noise(obs)
        
        # 5. Color jitter (action Î∂àÎ≥Ä)
        if np.random.random() < self.p_color_jitter:
            obs = self.color_jitter(obs)
        
        return obs, act
    
    def horizontal_flip(self, obs, action):
        """
        Horizontal flip
        
        Image: Ï¢åÏö∞ Î∞òÏ†Ñ
        Action: yÏ∂ï Í¥ÄÎ†® joint Î∞òÏ†Ñ
        """
        # Flip image
        if 'rgb' in obs:
            obs['rgb'] = np.fliplr(obs['rgb'])
        
        if 'depth' in obs:
            obs['depth'] = np.fliplr(obs['depth'])
        
        # Flip action (ÏòàÏãú, Ïã§Ï†úÎäî robot kinematicsÏóê Îî∞Îùº)
        # Joint 2, 4, 6: yÏ∂ï Í¥ÄÎ†®
        action[[1, 3, 5]] = -action[[1, 3, 5]]
        
        return obs, action
    
    def rotate(self, obs, action, angle):
        """
        Small rotation
        
        Image: ÌöåÏ†Ñ
        Action: base frame Í∏∞Ï§Ä ÌöåÏ†Ñ
        """
        import cv2
        from scipy.spatial.transform import Rotation
        
        # Rotate image
        if 'rgb' in obs:
            h, w = obs['rgb'].shape[:2]
            M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1.0)
            obs['rgb'] = cv2.warpAffine(obs['rgb'], M, (w, h))
        
        # Rotate action (Cartesian spaceÏóêÏÑú)
        # Joint spaceÎ©¥ FK ‚Üí rotate ‚Üí IK ÌïÑÏöî
        # Ïó¨Í∏∞ÏÑúÎäî Í∞ÑÎã®Ìûà approximation
        rot = Rotation.from_euler('z', angle, degrees=True)
        
        # ActionÏùò Ï≤òÏùå 3Í∞úÍ∞Ä xyzÎùºÍ≥† Í∞ÄÏ†ï
        if len(action) >= 3:
            action[:3] = rot.apply(action[:3])
        
        return obs, action
    
    def adjust_brightness(self, obs):
        """
        Brightness adjustment
        """
        if 'rgb' in obs:
            factor = np.random.uniform(0.7, 1.3)
            obs['rgb'] = np.clip(obs['rgb'] * factor, 0, 255).astype(np.uint8)
        
        return obs
    
    def add_noise(self, obs):
        """
        Gaussian noise
        """
        if 'rgb' in obs:
            noise = np.random.normal(0, 5, obs['rgb'].shape)
            obs['rgb'] = np.clip(obs['rgb'] + noise, 0, 255).astype(np.uint8)
        
        return obs
    
    def color_jitter(self, obs):
        """
        Color jittering
        """
        if 'rgb' in obs:
            # Hue, Saturation, Value adjustments
            import cv2
            
            hsv = cv2.cvtColor(obs['rgb'], cv2.COLOR_RGB2HSV).astype(np.float32)
            
            # Hue shift
            hsv[:, :, 0] += np.random.uniform(-10, 10)
            hsv[:, :, 0] = np.clip(hsv[:, :, 0], 0, 180)
            
            # Saturation
            hsv[:, :, 1] *= np.random.uniform(0.8, 1.2)
            hsv[:, :, 1] = np.clip(hsv[:, :, 1], 0, 255)
            
            # Value
            hsv[:, :, 2] *= np.random.uniform(0.8, 1.2)
            hsv[:, :, 2] = np.clip(hsv[:, :, 2], 0, 255)
            
            obs['rgb'] = cv2.cvtColor(hsv.astype(np.uint8), cv2.COLOR_HSV2RGB)
        
        return obs

# Dataset with augmentation
class AugmentedRobotDataset(Dataset):
    def __init__(self, episodes, augmentation=None):
        self.episodes = episodes
        self.augmentation = augmentation
        
        # Flatten to (obs, action) pairs
        self.data = []
        for ep in episodes:
            for step in ep['data']:
                self.data.append((
                    step['observation'],
                    step['action']
                ))
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        obs, action = self.data[idx]
        
        # Augmentation
        if self.augmentation:
            obs, action = self.augmentation.augment(obs, action)
        
        # Preprocessing
        obs_tensor = self.preprocess(obs)
        action_tensor = torch.FloatTensor(action)
        
        return obs_tensor, action_tensor
```

---

**Îç∞Ïù¥ÌÑ∞ ÏàòÏßë Í∞ÄÏù¥Îìú**
```
Î™©Ìëú: 50-100 ÏÑ±Í≥µ ÏóêÌîºÏÜåÎìú

Îã§ÏñëÏÑ± ÌôïÎ≥¥:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ 1. Î∞ïÏä§ ÏúÑÏπò: 5-7 ÏúÑÏπò          ‚îÇ
‚îÇ 2. Î∞ïÏä§ Î∞©Ìñ•: 4 Î∞©Ìñ• (90ÎèÑÏî©)   ‚îÇ
‚îÇ 3. Ï°∞Î™Ö Ï°∞Í±¥: 3 Îã®Í≥Ñ            ‚îÇ
‚îÇ 4. ÏãúÏûë ÏûêÏÑ∏: Îã§ÏñëÌïòÍ≤å           ‚îÇ
‚îÇ 5. ÏÜçÎèÑ: Îπ†Î•¥Í≤å/ÎäêÎ¶¨Í≤å          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

ÏãúÍ∞Ñ Ìà¨Ïûê:
- Ï£ºÎßê 4-6ÏãúÍ∞Ñ √ó 2Ï£º
- Ìïú ÏóêÌîºÏÜåÎìú: 2-3Î∂Ñ
- ‚Üí 50+ ÏóêÌîºÏÜåÎìú Ï∂©Î∂Ñ

Ï≤¥ÌÅ¨Î¶¨Ïä§Ìä∏:
- [ ] Teleoperation ÏãúÏä§ÌÖú ÏûëÎèô
- [ ] ÏµúÏÜå 50 ÏóêÌîºÏÜåÎìú ÏàòÏßë
- [ ] Îã§ÏñëÌïú Ï°∞Í±¥ Ìè¨Ìï®
- [ ] ÌíàÏßà Í≤ÄÏ¶ù ÏôÑÎ£å
- [ ] Îç∞Ïù¥ÌÑ∞ Ï†ÄÏû• ÌôïÏù∏
```

**ÏãúÍ∞Ñ: Ï£º 8-10ÏãúÍ∞Ñ (Ïã§Ï†ú ÏàòÏßë Ìè¨Ìï®)**

### Week 3-4: VLA ÌïôÏäµ

#### Î™®Îç∏ ÏÑ†ÌÉù Î∞è ÏÑ§Ï†ï
```python
# model_selection.py

"""
VLA Model ÏÑ†ÌÉù Í∞ÄÏù¥Îìú

Option 1: ACT (Action Chunking Transformer) - Ï∂îÏ≤ú!
- Ïû•Ï†ê: ÏïàÏ†ïÏ†Å ÌïôÏäµ, Temporal consistency, Ï¢ãÏùÄ ÏÑ±Îä•
- Îã®Ï†ê: Î©îÎ™®Î¶¨ ÏÇ¨Ïö©Îüâ ÎÜíÏùå
- Ï†ÅÌï©: ÎåÄÎ∂ÄÎ∂ÑÏùò manipulation tasks

Option 2: Diffusion Policy
- Ïû•Ï†ê: Multi-modal action, Îß§Ïö∞ ÏïàÏ†ïÏ†Å
- Îã®Ï†ê: Ï∂îÎ°† ÎäêÎ¶º (iterative denoising)
- Ï†ÅÌï©: High-precision tasks

Option 3: OpenVLA
- Ïû•Ï†ê: Pre-trained, Language conditioning
- Îã®Ï†ê: ÌÅ¨Í≥† Î¨¥Í±∞ÏõÄ, Fine-tuning Ïñ¥Î†§ÏõÄ
- Ï†ÅÌï©: Multi-task, zero-shot generalization

Ï∂îÏ≤ú: ACTÎ°ú ÏãúÏûë
‚Üí ÏïàÏ†ïÏ†ÅÏù¥Í≥† Îπ†Î¶Ñ
‚Üí ÎÇòÏ§ëÏóê Îã§Î•∏ policy ÎπÑÍµê
"""

# ACT Configuration
config = {
    'policy': 'act',
    'dataset': 'box_picking_v1',
    
    # Model architecture
    'vision_encoder': 'vit-base',
    'hidden_dim': 512,
    'n_heads': 8,
    'n_encoder_layers': 4,
    'n_decoder_layers': 1,
    'n_action_steps': 10,  # Action chunking
    'n_obs_steps': 1,
    
    # Action space
    'action_dim': 7,
    'action_type': 'delta_joint',
    
    # Observation
    'use_rgb': True,
    'use_depth': False,
    'use_proprio': True,
    
    # Training
    'batch_size': 32,
    'learning_rate': 1e-4,
    'num_epochs': 500,
    'weight_decay': 1e-4,
    'gradient_clip': 1.0,
    
    # Data augmentation
    'use_augmentation': True,
    'aug_prob': 0.5,
    
    # Hardware
    'device': 'cuda',
    'num_workers': 4,
    'mixed_precision': True,
    
    # Checkpointing
    'save_every': 50,
    'validate_every': 10,
}
```

---

#### ACT Î™®Îç∏ Íµ¨ÌòÑ
```python
# act_model.py
import torch
import torch.nn as nn
from transformers import ViTModel

class ACTPolicy(nn.Module):
    """
    Action Chunking Transformer
    
    Architecture:
    1. Vision Encoder (ViT)
    2. Proprioception Encoder (MLP)
    3. Encoder Transformer
    4. Decoder Transformer (action chunking)
    5. Action Head
    """
    
    def __init__(self, config):
        super().__init__()
        
        self.config = config
        self.hidden_dim = config['hidden_dim']
        self.n_action_steps = config['n_action_steps']
        self.action_dim = config['action_dim']
        
        # Vision Encoder
        self.vision_encoder = ViTModel.from_pretrained(
            'google/vit-base-patch16-224'
        )
        vision_dim = 768
        
        # Vision projection
        self.vision_proj = nn.Linear(vision_dim, self.hidden_dim)
        
        # Proprioception Encoder
        proprio_dim = 7 + 7 + 1  # joint_pos + joint_vel + gripper
        self.proprio_encoder = nn.Sequential(
            nn.Linear(proprio_dim, 128),
            nn.ReLU(),
            nn.Linear(128, self.hidden_dim)
        )
        
        # Encoder (process current observation)
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=self.hidden_dim,
            nhead=config['n_heads'],
            dim_feedforward=self.hidden_dim * 4,
            dropout=0.1,
            batch_first=True
        )
        self.encoder = nn.TransformerEncoder(
            encoder_layer,
            num_layers=config['n_encoder_layers']
        )
        
        # Decoder (generate action sequence)
        decoder_layer = nn.TransformerDecoderLayer(
            d_model=self.hidden_dim,
            nhead=config['n_heads'],
            dim_feedforward=self.hidden_dim * 4,
            dropout=0.1,
            batch_first=True
        )
        self.decoder = nn.TransformerDecoder(
            decoder_layer,
            num_layers=config['n_decoder_layers']
        )
        
        # Action queries (learnable)
        self.action_queries = nn.Parameter(
            torch.randn(1, self.n_action_steps, self.hidden_dim)
        )
        
        # Action Head
        self.action_head = nn.Linear(self.hidden_dim, self.action_dim)
        
        # Initialize weights
        self.apply(self._init_weights)
    
    def _init_weights(self, module):
        if isinstance(module, nn.Linear):
            torch.nn.init.xavier_uniform_(module.weight)
            if module.bias is not None:
                module.bias.data.zero_()
    
    def forward(self, observations):
        """
        Forward pass
        
        Args:
            observations: dict with
                - 'rgb': (B, 3, 224, 224)
                - 'proprio': (B, 15)
        
        Returns:
            actions: (B, n_action_steps, action_dim)
        """
        batch_size = observations['rgb'].shape[0]
        
        # 1. Encode vision
        vision_features = self.vision_encoder(
            observations['rgb']
        ).last_hidden_state  # (B, num_patches, 768)
        
        vision_features = self.vision_proj(vision_features)  # (B, N, hidden_dim)
        
        # 2. Encode proprioception
        proprio_features = self.proprio_encoder(
            observations['proprio']
        ).unsqueeze(1)  # (B, 1, hidden_dim)
        
        # 3. Concatenate features
        encoder_input = torch.cat([
            vision_features,
            proprio_features
        ], dim=1)  # (B, N+1, hidden_dim)
        
        # 4. Encoder
        encoder_output = self.encoder(encoder_input)  # (B, N+1, hidden_dim)
        
        # 5. Prepare action queries
        action_queries = self.action_queries.expand(
            batch_size, -1, -1
        )  # (B, n_action_steps, hidden_dim)
        
        # 6. Decoder
        decoder_output = self.decoder(
            action_queries,
            encoder_output
        )  # (B, n_action_steps, hidden_dim)
        
        # 7. Action prediction
        actions = self.action_head(decoder_output)  # (B, n_action_steps, action_dim)
        
        return actions
    
    def predict(self, observations):
        """
        Inference mode
        """
        self.eval()
        with torch.no_grad():
            actions = self.forward(observations)
        return actions
```

---

#### ÌïôÏäµ Ïä§ÌÅ¨Î¶ΩÌä∏
```python
# train.py
import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torch.cuda.amp import autocast, GradScaler
import wandb
from tqdm import tqdm

class VLATrainer:
    """
    VLA Training Pipeline
    """
    
    def __init__(self, config):
        self.config = config
        self.device = torch.device(config['device'])
        
        # Model
        self.model = ACTPolicy(config).to(self.device)
        
        # Optimizer
        self.optimizer = torch.optim.AdamW(
            self.model.parameters(),
            lr=config['learning_rate'],
            weight_decay=config['weight_decay']
        )
        
        # Scheduler
        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
            self.optimizer,
            T_max=config['num_epochs'],
            eta_min=config['learning_rate'] / 10
        )
        
        # Loss
        self.criterion = nn.MSELoss()
        
        # Mixed precision
        self.scaler = GradScaler() if config['mixed_precision'] else None
        
        # Logging
        if config.get('use_wandb', True):
            wandb.init(
                project='box-picking-vla',
                config=config
            )
        
        # Metrics
        self.best_val_loss = float('inf')
    
    def train_epoch(self, train_loader):
        """
        Single training epoch
        """
        self.model.train()
        
        total_loss = 0
        pbar = tqdm(train_loader, desc='Training')
        
        for batch_idx, (observations, actions) in enumerate(pbar):
            # Move to device
            observations = {
                k: v.to(self.device) for k, v in observations.items()
            }
            actions = actions.to(self.device)  # (B, n_action_steps, action_dim)
            
            # Forward
            if self.scaler:
                with autocast():
                    pred_actions = self.model(observations)
                    loss = self.criterion(pred_actions, actions)
                
                # Backward
                self.optimizer.zero_grad()
                self.scaler.scale(loss).backward()
                
                # Gradient clipping
                self.scaler.unscale_(self.optimizer)
                torch.nn.utils.clip_grad_norm_(
                    self.model.parameters(),
                    self.config['gradient_clip']
                )
                
                # Update
                self.scaler.step(self.optimizer)
                self.scaler.update()
            else:
                pred_actions = self.model(observations)
                loss = self.criterion(pred_actions, actions)
                
                self.optimizer.zero_grad()
                loss.backward()
                torch.nn.utils.clip_grad_norm_(
                    self.model.parameters(),
                    self.config['gradient_clip']
                )
                self.optimizer.step()
            
            # Metrics
            total_loss += loss.item()
            
            # Update progress bar
            pbar.set_postfix({'loss': f'{loss.item():.4f}'})
            
            # Log to wandb
            if self.config.get('use_wandb') and batch_idx % 10 == 0:
                wandb.log({
                    'train/loss': loss.item(),
                    'train/lr': self.optimizer.param_groups[0]['lr']
                })
        
        avg_loss = total_loss / len(train_loader)
        return avg_loss
    
    def validate(self, val_loader):
        """
        Validation
        """
        self.model.eval()
        
        total_loss = 0
        
        with torch.no_grad():
            for observations, actions in tqdm(val_loader, desc='Validation'):
                # Move to device
                observations = {
                    k: v.to(self.device) for k, v in observations.items()
                }
                actions = actions.to(self.device)
                
                # Forward
                pred_actions = self.model(observations)
                loss = self.criterion(pred_actions, actions)
                
                total_loss += loss.item()
        
        avg_loss = total_loss / len(val_loader)
        
        # Log
        if self.config.get('use_wandb'):
            wandb.log({'val/loss': avg_loss})
        
        return avg_loss
    
    def train(self, train_loader, val_loader):
        """
        Complete training loop
        """
        print("="*60)
        print("Starting Training")
        print("="*60)
        print(f"Model parameters: {sum(p.numel() for p in self.model.parameters()):,}")
        print(f"Training samples: {len(train_loader.dataset)}")
        print(f"Validation samples: {len(val_loader.dataset)}")
        print(f"Batch size: {self.config['batch_size']}")
        print(f"Epochs: {self.config['num_epochs']}")
        print("="*60)
        
        for epoch in range(self.config['num_epochs']):
            print(f"\nEpoch {epoch + 1}/{self.config['num_epochs']}")
            
            # Train
            train_loss = self.train_epoch(train_loader)
            
            # Validate
            if (epoch + 1) % self.config['validate_every'] == 0:
                val_loss = self.validate(val_loader)
                
                print(f"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}")
                
                # Save best model
                if val_loss < self.best_val_loss:
                    self.best_val_loss = val_loss
                    self.save_checkpoint('best_model.pt', epoch, val_loss)
                    print(f"‚úÖ Best model saved! (Val Loss: {val_loss:.4f})")
            
            # Save checkpoint
            if (epoch + 1) % self.config['save_every'] == 0:
                self.save_checkpoint(f'checkpoint_epoch{epoch+1}.pt', epoch, train_loss)
            
            # Update scheduler
            self.scheduler.step()
        
        print("\n" + "="*60)
        print("Training Complete!")
        print(f"Best Validation Loss: {self.best_val_loss:.4f}")
        print("="*60)
    
    def save_checkpoint(self, filename, epoch, loss):
        """
        Save model checkpoint
        """
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'loss': loss,
            'config': self.config
        }
        
        if self.scaler:
            checkpoint['scaler_state_dict'] = self.scaler.state_dict()
        
        torch.save(checkpoint, filename)
        print(f"üíæ Checkpoint saved: {filename}")
    
    def load_checkpoint(self, filename):
        """
        Load model checkpoint
        """
        checkpoint = torch.load(filename, map_location=self.device)
        
        self.model.load_state_dict(checkpoint['model_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
        
        if self.scaler and 'scaler_state_dict' in checkpoint:
            self.scaler.load_state_dict(checkpoint['scaler_state_dict'])
        
        print(f"‚úÖ Checkpoint loaded: {filename}")
        print(f"   Epoch: {checkpoint['epoch']}")
        print(f"   Loss: {checkpoint['loss']:.4f}")
        
        return checkpoint['epoch']

# Main training script
def main():
    # Load data
    from dataset import BoxPickingDataset
    
    train_dataset = BoxPickingDataset(
        'data/train_episodes.pkl',
        augmentation=True
    )
    
    val_dataset = BoxPickingDataset(
        'data/val_episodes.pkl',
        augmentation=False
    )
    
    train_loader = DataLoader(
        train_dataset,
        batch_size=config['batch_size'],
        shuffle=True,
        num_workers=config['num_workers'],
        pin_memory=True,
        persistent_workers=True
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=config['batch_size'],
        shuffle=False,
        num_workers=config['num_workers'],
        pin_memory=True
    )
    
    # Train
    trainer = VLATrainer(config)
    trainer.train(train_loader, val_loader)

if __name__ == '__main__':
    main()
```

---

#### Hyperparameter Tuning
```python
# hyperparameter_tuning.py

class LRFinder:
    """
    Learning Rate Finder
    
    Î™©Ï†Å: Optimal learning rate Ï∞æÍ∏∞
    Î∞©Î≤ï: Exponentially increasing LR, plot loss
    """
    
    def __init__(self, model, optimizer, criterion, device):
        self.model = model
        self.optimizer = optimizer
        self.criterion = criterion
        self.device = device
    
    def find(self, train_loader, min_lr=1e-7, max_lr=1, num_steps=100):
        """
        Run LR finder
        
        Returns:
            lrs: list of learning rates
            losses: list of losses
        """
        # Save initial state
        initial_state = {
            'model': self.model.state_dict(),
            'optimizer': self.optimizer.state_dict()
        }
        
        # LR schedule
        lrs = np.logspace(np.log10(min_lr), np.log10(max_lr), num_steps)
        losses = []
        
        # Iterator
        data_iter = iter(train_loader)
        
        for lr in tqdm(lrs, desc='LR Finder'):
            # Set LR
            for param_group in self.optimizer.param_groups:
                param_group['lr'] = lr
            
            # Get batch
            try:
                observations, actions = next(data_iter)
            except StopIteration:
                data_iter = iter(train_loader)
                observations, actions = next(data_iter)
            
            # Move to device
            observations = {k: v.to(self.device) for k, v in observations.items()}
            actions = actions.to(self.device)
            
            # Forward
            self.optimizer.zero_grad()
            pred_actions = self.model(observations)
            loss = self.criterion(pred_actions, actions)
            
            # Backward
            loss.backward()
            self.optimizer.step()
            
            # Record
            losses.append(loss.item())
            
            # Stop if loss explodes
            if len(losses) > 1 and losses[-1] > losses[0] * 10:
                break
        
        # Restore initial state
        self.model.load_state_dict(initial_state['model'])
        self.optimizer.load_state_dict(initial_state['optimizer'])
        
        # Plot
        self.plot(lrs[:len(losses)], losses)
        
        # Find optimal LR
        optimal_lr = self.find_optimal_lr(lrs[:len(losses)], losses)
        
        return lrs[:len(losses)], losses, optimal_lr
    
    def plot(self, lrs, losses):
        """
        Plot LR vs Loss
        """
        import matplotlib.pyplot as plt
        
        plt.figure(figsize=(10, 6))
        plt.plot(lrs, losses)
        plt.xscale('log')
        plt.xlabel('Learning Rate')
        plt.ylabel('Loss')
        plt.title('Learning Rate Finder')
        plt.grid(True)
        plt.savefig('lr_finder.png')
        plt.show()
    
    def find_optimal_lr(self, lrs, losses):
        """
        Find optimal LR (steepest descent point)
        """
        # Smooth losses
        from scipy.ndimage import gaussian_filter1d
        smoothed = gaussian_filter1d(losses, sigma=2)
        
        # Find steepest descent
        gradients = np.gradient(smoothed)
        optimal_idx = np.argmin(gradients)
        
        optimal_lr = lrs[optimal_idx]
        
        print(f"Optimal LR: {optimal_lr:.2e}")
        
        return optimal_lr

# Hyperparameter Grid Search
def grid_search():
    """
    Grid search for hyperparameters
    """
    
    param_grid = {
        'learning_rate': [1e-5, 3e-5, 1e-4, 3e-4],
        'batch_size': [16, 32, 64],
        'hidden_dim': [256, 512, 768],
        'n_action_steps': [5, 10, 15]
    }
    
    results = []
    
    for lr in param_grid['learning_rate']:
        for bs in param_grid['batch_size']:
            for hd in param_grid['hidden_dim']:
                for steps in param_grid['n_action_steps']:
                    print(f"\n{'='*60}")
                    print(f"Testing: lr={lr}, bs={bs}, hd={hd}, steps={steps}")
                    print(f"{'='*60}")
                    
                    # Update config
                    config.update({
                        'learning_rate': lr,
                        'batch_size': bs,
                        'hidden_dim': hd,
                        'n_action_steps': steps
                    })
                    
                    # Train
                    trainer = VLATrainer(config)
                    trainer.train(train_loader, val_loader)
                    
                    # Evaluate
                    val_loss = trainer.best_val_loss
                    
                    results.append({
                        'config': config.copy(),
                        'val_loss': val_loss
                    })
                    
                    print(f"Val Loss: {val_loss:.4f}")
    
    # Find best
    best = min(results, key=lambda x: x['val_loss'])
    
    print("\n" + "="*60)
    print("BEST CONFIGURATION")
    print("="*60)
    print(f"Val Loss: {best['val_loss']:.4f}")
    print(f"Config: {best['config']}")
    
    return results

# Optuna for automatic tuning
def optuna_tuning():
    """
    Optuna for hyperparameter optimization
    """
    import optuna
    
    def objective(trial):
        # Suggest hyperparameters
        lr = trial.suggest_loguniform('lr', 1e-5, 1e-3)
        batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])
        hidden_dim = trial.suggest_categorical('hidden_dim', [256, 512, 768])
        n_action_steps = trial.suggest_int('n_action_steps', 5, 15)
        
        # Update config
        config.update({
            'learning_rate': lr,
            'batch_size': batch_size,
            'hidden_dim': hidden_dim,
            'n_action_steps': n_action_steps
        })
        
        # Train
        trainer = VLATrainer(config)
        trainer.train(train_loader, val_loader)
        
        # Return validation loss
        return trainer.best_val_loss
    
    # Create study
    study = optuna.create_study(direction='minimize')
    study.optimize(objective, n_trials=20)
    
    # Best parameters
    print("\n" + "="*60)
    print("BEST PARAMETERS (Optuna)")
    print("="*60)
    print(f"Best Val Loss: {study.best_value:.4f}")
    print(f"Best Params: {study.best_params}")
    
    return study
```

---

#### ÌïôÏäµ Î™®ÎãàÌÑ∞ÎßÅ
```python
# monitoring.py

class TrainingMonitor:
    """
    ÌïôÏäµ Î™®ÎãàÌÑ∞ÎßÅ Î∞è ÏßÑÎã®
    """
    
    def __init__(self, log_dir='logs'):
        self.log_dir = log_dir
        os.makedirs(log_dir, exist_ok=True)
        
        self.metrics = {
            'train_loss': [],
            'val_loss': [],
            'learning_rate': [],
            'gradient_norm': []
        }
    
    def log_metrics(self, epoch, metrics):
        """
        Log metrics
        """
        for key, value in metrics.items():
            if key in self.metrics:
                self.metrics[key].append(value)
    
    def plot_training_curves(self):
        """
        Plot training curves
        """
        import matplotlib.pyplot as plt
        
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        
        # Loss curves
        axes[0, 0].plot(self.metrics['train_loss'], label='Train')
        axes[0, 0].plot(self.metrics['val_loss'], label='Val')
        axes[0, 0].set_xlabel('Epoch')
        axes[0, 0].set_ylabel('Loss')
        axes[0, 0].set_title('Loss Curves')
        axes[0, 0].legend()
        axes[0, 0].grid(True)
        
        # Learning rate
        axes[0, 1].plot(self.metrics['learning_rate'])
        axes[0, 1].set_xlabel('Epoch')
        axes[0, 1].set_ylabel('Learning Rate')
        axes[0, 1].set_title('Learning Rate Schedule')
        axes[0, 1].set_yscale('log')
        axes[0, 1].grid(True)
        
        # Gradient norm
        axes[1, 0].plot(self.metrics['gradient_norm'])
        axes[1, 0].set_xlabel('Epoch')
        axes[1, 0].set_ylabel('Gradient Norm')
        axes[1, 0].set_title('Gradient Norm')
        axes[1, 0].grid(True)
        
        # Overfitting detection
        train_loss = np.array(self.metrics['train_loss'])
        val_loss = np.array(self.metrics['val_loss'])
        gap = val_loss - train_loss
        
        axes[1, 1].plot(gap)
        axes[1, 1].axhline(y=0, color='r', linestyle='--')
        axes[1, 1].set_xlabel('Epoch')
        axes[1, 1].set_ylabel('Val - Train Loss')
        axes[1, 1].set_title('Overfitting Detection')
        axes[1, 1].grid(True)
        
        plt.tight_layout()
        plt.savefig(f'{self.log_dir}/training_curves.png')
        plt.show()
    
    def check_overfitting(self):
        """
        Overfitting Í∞êÏßÄ
        """
        train_loss = np.array(self.metrics['train_loss'])
        val_loss = np.array(self.metrics['val_loss'])
        
        # Recent trend
        recent_window = 10
        if len(val_loss) >= recent_window:
            recent_train = train_loss[-recent_window:]
            recent_val = val_loss[-recent_window:]
            
            # Check if val loss is increasing while train loss decreases
            train_trend = np.polyfit(range(recent_window), recent_train, 1)[0]
            val_trend = np.polyfit(range(recent_window), recent_val, 1)[0]
            
            if train_trend < 0 and val_trend > 0:
                print("‚ö†Ô∏è Overfitting detected!")
                print(f"   Train trend: {train_trend:.6f}")
                print(f"   Val trend: {val_trend:.6f}")
                
                print("\nÌï¥Í≤∞Ï±Ö:")
                print("1. Îçî ÎßéÏùÄ Îç∞Ïù¥ÌÑ∞ ÏàòÏßë")
                print("2. Data augmentation Í∞ïÌôî")
                print("3. Dropout Ï¶ùÍ∞Ä")
                print("4. Weight decay Ï¶ùÍ∞Ä")
                print("5. Early stopping")
                
                return True
        
        return False

# ÌïôÏäµ Ï§ë Ï≤¥ÌÅ¨Î¶¨Ïä§Ìä∏
monitoring_checklist = """
Îß§ 10 epochÎßàÎã§ Ï≤¥ÌÅ¨:
- [ ] Training loss Í∞êÏÜå Ï§ë?
- [ ] Validation loss overfitting?
- [ ] Action Î∂ÑÌè¨ Ï†ïÏÉÅ? (ÏãúÍ∞ÅÌôî)
- [ ] Gradient norm ÏïàÏ†ï? (< 10)
- [ ] Learning rate Ï†ÅÏ†à?
- [ ] GPU Î©îÎ™®Î¶¨ ÏÇ¨Ïö©Î•†?

Î¨∏Ï†ú Î∞úÏÉù Ïãú:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Loss Ìè≠Î∞ú                               ‚îÇ
‚îÇ ‚Üí LR ÎÇÆÏ∂îÍ∏∞ (1/10)                      ‚îÇ
‚îÇ ‚Üí Gradient clipping ÌôïÏù∏                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Loss Ï†ïÏ≤¥                               ‚îÇ
‚îÇ ‚Üí LR ÎÜíÏù¥Í∏∞ or schedule Ï°∞Ï†ï            ‚îÇ
‚îÇ ‚Üí Augmentation Í∞ïÌôî                     ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Overfitting                             ‚îÇ
‚îÇ ‚Üí Dropout Ï∂îÍ∞Ä                          ‚îÇ
‚îÇ ‚Üí Weight decay Ï¶ùÍ∞Ä                     ‚îÇ
‚îÇ ‚Üí Îç∞Ïù¥ÌÑ∞ Ï∂îÍ∞Ä ÏàòÏßë                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Action Ïù¥ÏÉÅ (Î™®Îëê ÎπÑÏä∑)                 ‚îÇ
‚îÇ ‚Üí Action normalization ÌôïÏù∏             ‚îÇ
‚îÇ ‚Üí Îç∞Ïù¥ÌÑ∞ Î∂àÍ∑†Ìòï Ï≤¥ÌÅ¨                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
"""
```

**ÏãúÍ∞Ñ: Ï£º 8-10ÏãúÍ∞Ñ (ÌïôÏäµ ÏãúÍ∞Ñ Ìè¨Ìï®)**

---

### Week 5-6: ÌèâÍ∞Ä Î∞è ÎîîÎ≤ÑÍπÖ

#### Ï¢ÖÌï© ÌèâÍ∞Ä ÏãúÏä§ÌÖú
```python
# evaluation.py

class VLAEvaluator:
    """
    Îã§Ï∞®Ïõê VLA ÌèâÍ∞Ä
    
    Metrics:
    1. Success Rate (Í∞ÄÏû• Ï§ëÏöî!)
    2. Completion Time
    3. Trajectory Smoothness
    4. Safety (collisions)
    5. Efficiency
    """
    
    def __init__(self, model, env, device='cuda'):
        self.model = model
        self.env = env
        self.device = device
        
        self.model.eval()
    
    def evaluate_episode(self, episode_data):
        """
        Îã®Ïùº ÏóêÌîºÏÜåÎìú ÌèâÍ∞Ä
        
        Args:
            episode_data: dict with trajectory info
        
        Returns:
            metrics: dict
        """
        metrics = {}
        
        # 1. Success
        metrics['success'] = episode_data['success']
        
        # 2. Completion Time
        metrics['time'] = episode_data['num_steps'] * 0.1  # seconds
        
        # 3. Trajectory Smoothness (jerk)
        actions = np.array(episode_data['actions'])
        velocities = np.diff(actions, axis=0)
        jerks = np.diff(velocities, axis=0)
        metrics['smoothness'] = -np.mean(np.abs(jerks))  # ÎÇÆÏùÑÏàòÎ°ù Î∂ÄÎìúÎü¨ÏõÄ
        metrics['max_jerk'] = np.max(np.abs(jerks))
        
        # 4. Safety
        metrics['num_collisions'] = episode_data['collision_count']
        metrics['max_joint_velocity'] = np.max(np.abs(velocities))
        
        # 5. Efficiency
        if episode_data['success']:
            optimal_time = 5.0  # seconds (baseline)
            metrics['efficiency'] = min(optimal_time / metrics['time'], 1.0)
        else:
            metrics['efficiency'] = 0.0
        
        # 6. Distance to goal (final)
        metrics['final_distance'] = episode_data.get('final_distance', 1.0)
        
        # 7. Action magnitude
        metrics['avg_action_magnitude'] = np.mean(np.abs(actions))
        
        return metrics
    
    def run_evaluation(self, num_episodes=20):
        """
        Ï†ÑÏ≤¥ ÌèâÍ∞Ä Ïã§Ìñâ
        
        Args:
            num_episodes: number of test episodes
        
        Returns:
            summary: aggregated metrics
        """
        all_metrics = []
        
        print(f"\n{'='*60}")
        print(f"Running Evaluation ({num_episodes} episodes)")
        print(f"{'='*60}")
        
        for ep in range(num_episodes):
            print(f"\nEpisode {ep + 1}/{num_episodes}")
            
            # Reset environment
            obs = self.env.reset()
            done = False
            step = 0
            max_steps = 200
            
            episode_data = {
                'actions': [],
                'observations': [],
                'collision_count': 0,
                'success': False,
                'num_steps': 0
            }
            
            # Rollout
            action_buffer = []  # For action chunking
            
            while not done and step < max_steps:
                # Get action (with chunking)
                if len(action_buffer) == 0:
                    # Predict action chunk
                    obs_tensor = self.preprocess_observation(obs)
                    
                    with torch.no_grad():
                        action_chunk = self.model.predict(obs_tensor)
                    
                    action_buffer = list(action_chunk[0].cpu().numpy())
                
                # Pop next action
                action = action_buffer.pop(0)
                
                # Execute
                obs, reward, done, info = self.env.step(action)
                
                # Record
                episode_data['actions'].append(action)
                episode_data['observations'].append(obs)
                
                if info.get('collision'):
                    episode_data['collision_count'] += 1
                
                if info.get('success'):
                    episode_data['success'] = True
                    done = True
                
                step += 1
            
            episode_data['num_steps'] = step
            episode_data['final_distance'] = info.get('distance_to_goal', 1.0)
            
            # Evaluate episode
            metrics = self.evaluate_episode(episode_data)
            all_metrics.append(metrics)
            
            # Print
            status = "‚úÖ" if metrics['success'] else "‚ùå"
            print(f"{status} Success: {metrics['success']}, "
                  f"Time: {metrics['time']:.2f}s, "
                  f"Collisions: {metrics['num_collisions']}, "
                  f"Smoothness: {metrics['smoothness']:.4f}")
        
        # Aggregate
        summary = self.aggregate_results(all_metrics)
        
        return summary, all_metrics
    
    def aggregate_results(self, all_metrics):
        """
        Í≤∞Í≥º ÏßëÍ≥Ñ Î∞è Ï∂úÎ†•
        """
        summary = {
            'success_rate': np.mean([m['success'] for m in all_metrics]),
            'avg_time': np.mean([m['time'] for m in all_metrics]),
            'std_time': np.std([m['time'] for m in all_metrics]),
            'avg_smoothness': np.mean([m['smoothness'] for m in all_metrics]),
            'total_collisions': np.sum([m['num_collisions'] for m in all_metrics]),
            'avg_efficiency': np.mean([m['efficiency'] for m in all_metrics if m['efficiency'] > 0]),
            'avg_final_distance': np.mean([m['final_distance'] for m in all_metrics]),
            'max_jerk': np.max([m['max_jerk'] for m in all_metrics])
        }
        
        print("\n" + "="*60)
        print("EVALUATION SUMMARY")
        print("="*60)
        print(f"Success Rate:       {summary['success_rate']*100:5.1f}%")
        print(f"Avg Time:           {summary['avg_time']:5.2f}s (¬±{summary['std_time']:.2f})")
        print(f"Smoothness:         {summary['avg_smoothness']:5.4f}")
        print(f"Total Collisions:   {summary['total_collisions']:5.0f}")
        print(f"Avg Efficiency:     {summary['avg_efficiency']*100:5.1f}%")
        print(f"Avg Final Distance: {summary['avg_final_distance']:5.3f}m")
        print(f"Max Jerk:           {summary['max_jerk']:5.2f}")
        print("="*60)
        
        return summary
    
    def preprocess_observation(self, obs):
        """
        Preprocess observation for model
        """
        # Convert to tensor
        rgb = torch.FloatTensor(obs['rgb']).unsqueeze(0).to(self.device)
        proprio = torch.FloatTensor(obs['proprio']).unsqueeze(0).to(self.device)
        
        return {'rgb': rgb, 'proprio': proprio}
    
    def compare_checkpoints(self, checkpoint_paths):
        """
        Ïó¨Îü¨ checkpoint ÎπÑÍµê
        """
        results = {}
        
        for path in checkpoint_paths:
            print(f"\n{'='*60}")
            print(f"Evaluating: {path}")
            print(f"{'='*60}")
            
            # Load checkpoint
            checkpoint = torch.load(path)
            self.model.load_state_dict(checkpoint['model_state_dict'])
            
            # Evaluate
            summary, _ = self.run_evaluation(num_episodes=10)
            results[path] = summary
        
        # Visualize comparison
        self.plot_comparison(results)
        
        return results
    
    def plot_comparison(self, results):
        """
        Í≤∞Í≥º ÎπÑÍµê ÏãúÍ∞ÅÌôî
        """
        import matplotlib.pyplot as plt
        
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        
        checkpoints = list(results.keys())
        
        metrics = [
            ('success_rate', 'Success Rate'),
            ('avg_time', 'Avg Time (s)'),
            ('avg_smoothness', 'Smoothness'),
            ('total_collisions', 'Total Collisions'),
            ('avg_efficiency', 'Efficiency'),
            ('avg_final_distance', 'Final Distance (m)')
        ]
        
        for idx, (metric, title) in enumerate(metrics):
            ax = axes[idx // 3, idx % 3]
            
            values = [results[c][metric] for c in checkpoints]
            
            ax.bar(range(len(checkpoints)), values)
            ax.set_title(title)
            ax.set_xticks(range(len(checkpoints)))
            ax.set_xticklabels([f'CP{i+1}' for i in range(len(checkpoints))], rotation=45)
            
            # Add value labels
            for i, v in enumerate(values):
                ax.text(i, v, f'{v:.2f}', ha='center', va='bottom')
        
        plt.tight_layout()
        plt.savefig('checkpoint_comparison.png')
        plt.show()

# Generalization Test
def test_generalization(model, env):
    """
    ÌïôÏäµ Ï°∞Í±¥Í≥º Îã§Î•∏ ÌôòÍ≤ΩÏóêÏÑú ÌÖåÏä§Ìä∏
    """
    test_conditions = [
        {
            'name': 'baseline',
            'lighting': 'normal',
            'box_size': 'medium',
            'clutter': 'none'
        },
        {
            'name': 'bright_light',
            'lighting': 'bright',
            'box_size': 'medium',
            'clutter': 'none'
        },
        {
            'name': 'dim_light',
            'lighting': 'dim',
            'box_size': 'medium',
            'clutter': 'none'
        },
        {
            'name': 'large_box',
            'lighting': 'normal',
            'box_size': 'large',
            'clutter': 'none'
        },
        {
            'name': 'small_box',
            'lighting': 'normal',
            'box_size': 'small',
            'clutter': 'none'
        },
        {
            'name': 'high_clutter',
            'lighting': 'normal',
            'box_size': 'medium',
            'clutter': 'high'
        },
        {
            'name': 'combined_hard',
            'lighting': 'dim',
            'box_size': 'small',
            'clutter': 'medium'
        }
    ]
    
    results = {}
    evaluator = VLAEvaluator(model, env)
    
    for condition in test_conditions:
        print(f"\n{'='*60}")
        print(f"Testing: {condition['name']}")
        print(f"Condition: {condition}")
        print(f"{'='*60}")
        
        # Setup environment
        env.configure(condition)
        
        # Evaluate
        summary, _ = evaluator.run_evaluation(num_episodes=10)
        results[condition['name']] = summary
    
    # Plot generalization
    plot_generalization_results(results)
    
    return results

def plot_generalization_results(results):
    """
    Generalization Í≤∞Í≥º ÏãúÍ∞ÅÌôî
    """
    import matplotlib.pyplot as plt
    
    conditions = list(results.keys())
    success_rates = [results[c]['success_rate'] for c in conditions]
    
    plt.figure(figsize=(12, 6))
    bars = plt.bar(range(len(conditions)), success_rates)
    
    # Color code by performance
    for i, bar in enumerate(bars):
        if success_rates[i] > 0.7:
            bar.set_color('green')
        elif success_rates[i] > 0.5:
            bar.set_color('yellow')
        else:
            bar.set_color('red')
    
    plt.axhline(y=0.7, color='r', linestyle='--', label='Target (70%)')
    plt.xticks(range(len(conditions)), conditions, rotation=45, ha='right')
    plt.ylabel('Success Rate')
    plt.title('Generalization Performance')
    plt.legend()
    plt.tight_layout()
    plt.savefig('generalization_results.png')
    plt.show()
    
    # Analysis
    baseline = results['baseline']['success_rate']
    
    print("\n" + "="*60)
    print("GENERALIZATION ANALYSIS")
    print("="*60)
    print(f"Baseline: {baseline*100:.1f}%")
    print(f"\nPerformance Drops:")
    for name, result in results.items():
        if name != 'baseline':
            drop = (baseline - result['success_rate']) * 100
            print(f"  {name:20s}: {drop:+5.1f}%")
```

---

#### ÎîîÎ≤ÑÍπÖ Ï†ÑÎûµ
```python
# debugging.py

class VLADebugger:
    """
    VLA ÎîîÎ≤ÑÍπÖ ÎèÑÍµ¨
    """
    
    def __init__(self, model, dataloader):
        self.model = model
        self.dataloader = dataloader
    
    def debug_training(self):
        """
        ÌïôÏäµ ÎîîÎ≤ÑÍπÖ
        
        Î¨∏Ï†ú 1: LossÍ∞Ä Ïïà Îñ®Ïñ¥Ïßê
        """
        print("="*60)
        print("DEBUG: Training Issues")
        print("="*60)
        
        # Step 1: Overfit single batch
        print("\nStep 1: Overfitting single batch...")
        
        one_batch = next(iter(self.dataloader))
        obs, actions = one_batch
        
        self.model.train()
        optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)
        criterion = nn.MSELoss()
        
        losses = []
        for i in range(1000):
            pred = self.model(obs)
            loss = criterion(pred, actions)
            
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            losses.append(loss.item())
            
            if i % 100 == 0:
                print(f"  Step {i:4d}: Loss = {loss.item():.6f}")
        
        if losses[-1] < 0.01:
            print("‚úÖ Model CAN learn (loss ‚Üí 0)")
            print("   Problem is likely in data or training setup")
        else:
            print("‚ùå Model CANNOT learn from this batch")
            print("   Check:")
            print("   - Model architecture")
            print("   - Loss function")
            print("   - Learning rate (try 10x higher)")
        
        # Step 2: Data sanity check
        print("\nStep 2: Data sanity check...")
        
        print(f"  Observation keys: {obs.keys()}")
        print(f"  RGB shape: {obs['rgb'].shape}")
        print(f"  Action shape: {actions.shape}")
        print(f"  Action range: [{actions.min():.3f}, {actions.max():.3f}]")
        print(f"  Action mean: {actions.mean():.3f}")
        print(f"  Action std: {actions.std():.3f}")
        
        if actions.std() < 0.01:
            print("‚ö†Ô∏è Actions have very low variance!")
            print("   Data collection might be too uniform")
        
        # Step 3: Gradient check
        print("\nStep 3: Gradient check...")
        
        self.model.zero_grad()
        pred = self.model(obs)
        loss = criterion(pred, actions)
        loss.backward()
        
        grad_norms = {}
        for name, param in self.model.named_parameters():
            if param.grad is not None:
                grad_norm = param.grad.norm().item()
                grad_norms[name] = grad_norm
                
                if grad_norm > 100:
                    print(f"‚ö†Ô∏è Large gradient: {name:40s} = {grad_norm:.2f}")
                elif grad_norm < 1e-7:
                    print(f"‚ö†Ô∏è Tiny gradient: {name:40s} = {grad_norm:.2e}")
        
        # Step 4: Visualize predictions
        print("\nStep 4: Visualizing predictions...")
        self.visualize_predictions()
    
    def visualize_predictions(self):
        """
        ÏòàÏ∏° ÏãúÍ∞ÅÌôîÎ°ú Î¨∏Ï†ú ÌååÏïÖ
        """
        import matplotlib.pyplot as plt
        
        self.model.eval()
        
        fig, axes = plt.subplots(3, 5, figsize=(20, 12))
        
        with torch.no_grad():
            for idx, (obs, gt_actions) in enumerate(self.dataloader):
                if idx >= 5:
                    break
                
                # Predict
                pred_actions = self.model(obs)
                
                # First timestep only (for action chunking)
                gt_action = gt_actions[0, 0].cpu().numpy()
                pred_action = pred_actions[0, 0].cpu().numpy()
                
                # Row 1: Observation
                axes[0, idx].imshow(obs['rgb'][0].permute(1, 2, 0).cpu())
                axes[0, idx].set_title(f'Observation {idx+1}')
                axes[0, idx].axis('off')
                
                # Row 2: Ground truth action
                axes[1, idx].bar(range(7), gt_action)
                axes[1, idx].set_title('GT Action')
                axes[1, idx].set_ylim([-1, 1])
                axes[1, idx].set_xticks(range(7))
                axes[1, idx].set_xticklabels([f'J{i+1}' for i in range(7)])
                
                # Row 3: Predicted action
                axes[2, idx].bar(range(7), pred_action)
                axes[2, idx].set_title('Pred Action')
                axes[2, idx].set_ylim([-1, 1])
                axes[2, idx].set_xticks(range(7))
                axes[2, idx].set_xticklabels([f'J{i+1}' for i in range(7)])
        
        plt.tight_layout()
        plt.savefig('prediction_visualization.png')
        plt.show()
        
        # Ìå®ÌÑ¥ Î∂ÑÏÑù
        print("\nÍ¥ÄÏ∞∞ ÏÇ¨Ìï≠:")
        print("- Î™®Îì† actionÏù¥ ÎπÑÏä∑? ‚Üí Î™®Îç∏Ïù¥ ÌïôÏäµ Ïïà Îê®")
        print("- ÌäπÏ†ï jointÎßå ÏõÄÏßÅÏûÑ? ‚Üí Îç∞Ïù¥ÌÑ∞ Î∂àÍ∑†Ìòï")
        print("- Í∞íÏù¥ ÎÑàÎ¨¥ ÌÅº/ÏûëÏùå? ‚Üí Normalization Î¨∏Ï†ú")
        print("- GTÏôÄ ÏôÑÏ†ÑÌûà Îã§Î¶Ñ? ‚Üí Î™®Îç∏ capacity Î∂ÄÏ°±")
    
    def detect_overfitting(self, train_losses, val_losses):
        """
        Overfitting Í∞êÏßÄ Î∞è Ìï¥Í≤∞
        """
        import matplotlib.pyplot as plt
        
        plt.figure(figsize=(10, 6))
        plt.plot(train_losses, label='Train Loss')
        plt.plot(val_losses, label='Val Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.title('Training Progress')
        plt.legend()
        plt.grid(True)
        plt.savefig('loss_curves.png')
        plt.show()
        
        # Overfitting detection
        if len(val_losses) > 10:
            recent_val = val_losses[-10:]
            if recent_val[-1] > recent_val[0]:
                print("‚ö†Ô∏è Overfitting detected!")
                
                solutions = """
                Ìï¥Í≤∞Ï±Ö:
                1. Îçî ÎßéÏùÄ Îç∞Ïù¥ÌÑ∞ ÏàòÏßë (Í∞ÄÏû• Ìö®Í≥ºÏ†Å!)
                2. Data augmentation Í∞ïÌôî
                3. Dropout Ï∂îÍ∞Ä/Ï¶ùÍ∞Ä
                   - ÌòÑÏû¨ dropout=0.1 ‚Üí 0.2Î°ú
                4. Weight decay Ï¶ùÍ∞Ä
                   - ÌòÑÏû¨ weight_decay=1e-4 ‚Üí 1e-3Î°ú
                5. Î™®Îç∏ ÌÅ¨Í∏∞ Ï§ÑÏù¥Í∏∞
                   - hidden_dim: 512 ‚Üí 256
                6. Early stopping Ï†ÅÏö©
                   - patience=20
                7. Ensemble (Ïó¨Îü¨ checkpoint ÌèâÍ∑†)
                """
                print(solutions)
                
                # Early stopping checkpoint
                best_epoch = np.argmin(val_losses)
                print(f"\nÏµúÏ†Å checkpoint: Epoch {best_epoch+1}")
                print(f"Val Loss: {val_losses[best_epoch]:.4f}")
    
    def analyze_failure_cases(self, failed_episodes):
        """
        Ïã§Ìå® ÏºÄÏù¥Ïä§ Î∂ÑÏÑù
        """
        print("\n" + "="*60)
        print("FAILURE CASE ANALYSIS")
        print("="*60)
        
        # Classify failures
        failure_types = {
            'grasp_failure': 0,
            'collision': 0,
            'trajectory_deviation': 0,
            'timeout': 0,
            'other': 0
        }
        
        for episode in failed_episodes:
            failure_type = self.classify_failure(episode)
            failure_types[failure_type] += 1
        
        # Report
        total = len(failed_episodes)
        for failure_type, count in failure_types.items():
            percentage = (count / total * 100) if total > 0 else 0
            print(f"{failure_type:20s}: {count:3d} ({percentage:5.1f}%)")
        
        # Recommendations
        print("\n" + "="*60)
        print("RECOMMENDATIONS")
        print("="*60)
        
        if failure_types['grasp_failure'] > total * 0.3:
            print("Main issue: Grasp Failure")
            print("Solutions:")
            print("- Collect more grasp demonstrations")
            print("- Add grasp-specific augmentation")
            print("- Check gripper control")
        
        if failure_types['collision'] > total * 0.3:
            print("Main issue: Collisions")
            print("Solutions:")
            print("- Add safety constraints")
            print("- Reduce action magnitude limits")
            print("- Improve obstacle avoidance data")
        
        if failure_types['trajectory_deviation'] > total * 0.3:
            print("Main issue: Trajectory Deviation")
            print("Solutions:")
            print("- Increase action chunking length")
            print("- Add trajectory tracking loss")
            print("- Collect more diverse trajectories")
    
    def classify_failure(self, episode):
        """
        Ïã§Ìå® Ïú†Ìòï Î∂ÑÎ•ò
        """
        # Í∞ÑÎã®Ìïú Ìú¥Î¶¨Ïä§Ìã± Í∏∞Î∞ò Î∂ÑÎ•ò
        if episode.get('gripper_empty') and episode.get('attempted_grasp'):
            return 'grasp_failure'
        
        if episode.get('collision_count', 0) > 0:
            return 'collision'
        
        if episode.get('max_deviation', 0) > 0.5:
            return 'trajectory_deviation'
        
        if episode.get('timed_out'):
            return 'timeout'
        
        return 'other'
```

**Í∏∞ÎåÄ Í≤∞Í≥º Î∞è Í∞úÏÑ† Í∞ÄÏù¥Îìú**
```
Ï≤´ ÏãúÎèÑ Î™©Ìëú:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Success Rate:  40-60%          ‚îÇ
‚îÇ Completion Time: < 10s         ‚îÇ
‚îÇ Smooth trajectory              ‚îÇ
‚îÇ Zero collisions (safety)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Í∞úÏÑ† Î™©Ìëú (Îç∞Ïù¥ÌÑ∞/Î™®Îç∏ ÌäúÎãù ÌõÑ):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Success Rate:  70%+            ‚îÇ
‚îÇ Completion Time: 5-7s          ‚îÇ
‚îÇ Smooth & efficient             ‚îÇ
‚îÇ Robust to variations           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

60% ÎØ∏ÎßåÏù¥Î©¥:
‚Üí Îçî ÎßéÏùÄ Îç∞Ïù¥ÌÑ∞ (100+ episodes)
‚Üí Hyperparameter tuning
‚Üí Action space Ïû¨Ï†ïÏùò
‚Üí Observation Í∞úÏÑ†
```

**ÏãúÍ∞Ñ: Ï£º 8-10ÏãúÍ∞Ñ**

---

## Month 11-12: Í≥†ÎèÑÌôî Î∞è ROS2 ÌÜµÌï©

### Week 1-2: Ïã§Ìå® Î≥µÍµ¨ ÏãúÏä§ÌÖú
```python
# failure_recovery.py

class FailureRecovery:
    """
    Ïã§Ìå® Í∞êÏßÄ Î∞è Î≥µÍµ¨
    
    Î™©Ï†Å:
    - Ïã§Ìå® ÏÉÅÌô© ÏûêÎèô Í∞êÏßÄ
    - Î≥µÍµ¨ action ÏÉùÏÑ±
    - Retry logic
    - Safety monitoring
    """
    
    def __init__(self, policy, robot):
        self.policy = policy
        self.robot = robot
        self.max_retries = 3
        
        # Failure detectors
        self.collision_detector = CollisionDetector(robot)
        self.stuck_detector = StuckDetector(robot)
        self.grasp_detector = GraspDetector(robot)
    
    def detect_failure(self, obs, action, robot_state):
        """
        Ïã§Ìå® ÏÉÅÌô© Í∞êÏßÄ
        
        Returns:
            failure_type: str or None
            confidence: float (0-1)
        """
        failures = []
        
        # 1. Collision
        if self.collision_detector.check(robot_state):
            failures.append(('collision', 0.9))
        
        # 2. Grasp failure
        if self.grasp_detector.check_failure(obs, robot_state):
            failures.append(('grasp_failure', 0.8))
        
        # 3. Stuck
        if self.stuck_detector.check(robot_state):
            failures.append(('stuck', 0.7))
        
        # 4. Out of workspace
        if not self.is_in_workspace(robot_state['ee_position']):
            failures.append(('out_of_bounds', 0.9))
        
        # 5. Trajectory deviation (if tracking)
        if hasattr(self, 'expected_trajectory'):
            deviation = self.compute_deviation(robot_state)
            if deviation > 0.2:  # 20cm
                failures.append(('trajectory_deviation', 0.6))
        
        # Return highest confidence failure
        if failures:
            failures.sort(key=lambda x: x[1], reverse=True)
            return failures[0]
        
        return None, 0.0
    
    def recover(self, failure_type, robot_state):
        """
        Ïã§Ìå® Ïú†ÌòïÎ≥Ñ Î≥µÍµ¨ Ï†ÑÎûµ
        
        Args:
            failure_type: str
            robot_state: dict
        
        Returns:
            recovery_actions: list of actions
        """
        recovery_strategies = {
            'collision': self.recover_from_collision,
            'grasp_failure': self.retry_grasp,
            'stuck': self.jiggle,
            'out_of_bounds': self.return_to_safe_zone,
            'trajectory_deviation': self.replan
        }
        
        recovery_fn = recovery_strategies.get(failure_type)
        
        if recovery_fn:
            return recovery_fn(robot_state)
        
        return None
    
    def recover_from_collision(self, robot_state):
        """
        Ï∂©Îèå Î≥µÍµ¨: Îí§Î°ú ÌõÑÏßÑ
        """
        # ÎßàÏßÄÎßâ actionÏùò Î∞òÎåÄ Î∞©Ìñ•
        last_action = robot_state.get('last_action', np.zeros(7))
        
        # Retreat action (50% reverse)
        recovery_action = -0.5 * last_action
        
        # Execute for a few steps
        recovery_actions = [recovery_action] * 5
        
        return recovery_actions
    
    def retry_grasp(self, robot_state):
        """
        Grasp Ïû¨ÏãúÎèÑ: ÏïΩÍ∞Ñ Îã§Î•∏ Í∞ÅÎèÑÎ°ú
        """
        # Current EE pose
        current_pose = robot_state['ee_pose']
        
        # Add small random offset
        position_offset = np.random.normal(0, 0.02, 3)  # ¬±2cm
        orientation_offset = np.random.normal(0, 0.1, 4)  # small rotation
        
        # Compute recovery trajectory
        recovery_actions = self.plan_to_pose(
            current_pose[:3] + position_offset,
            current_pose[3:] + orientation_offset
        )
        
        # Add closing gripper at end
        recovery_actions.append(np.array([0, 0, 0, 0, 0, 0, 1.0]))
        
        return recovery_actions
    
    def jiggle(self, robot_state):
        """
        Stuck Ìï¥Ï†ú: ÏûëÏùÄ ÎûúÎç§ ÏõÄÏßÅÏûÑ
        """
        jiggle_actions = []
        
        for _ in range(3):
            action = np.random.uniform(-0.1, 0.1, 7)
            jiggle_actions.append(action)
        
        return jiggle_actions
    
    def return_to_safe_zone(self, robot_state):
        """
        ÏïàÏ†Ñ ÏòÅÏó≠ÏúºÎ°ú Î≥µÍ∑Ä
        """
        # Define safe pose (home position)
        safe_joint_positions = np.array([0, -0.5, 0, -1.5, 0, 1.0, 0])
        
        # Current position
        current = robot_state['joint_positions']
        
        # Plan trajectory to safe pose
        recovery_actions = self.plan_joint_trajectory(
            current,
            safe_joint_positions,
            num_steps=20
        )
        
        return recovery_actions
    
    def replan(self, robot_state):
        """
        Ïû¨Í≥ÑÌöç: ÏÉàÎ°úÏö¥ trajectory ÏÉùÏÑ±
        """
        # Get current observation
        obs = self.get_observation()
        
        # Re-predict with policy
        with torch.no_grad():
            new_actions = self.policy.predict(obs)
        
        return list(new_actions.cpu().numpy())
    
    def execute_with_recovery(self, obs, max_attempts=3):
        """
        Î≥µÍµ¨ Î°úÏßÅ Ìè¨Ìï® Ïã§Ìñâ
        
        Main execution loop with failure handling
        """
        for attempt in range(max_attempts):
            print(f"Attempt {attempt + 1}/{max_attempts}")
            
            # Normal execution
            action = self.policy.predict(obs)
            robot_state = self.execute_action(action)
            
            # Check for failure
            failure_type, confidence = self.detect_failure(
                obs, action, robot_state
            )
            
            if failure_type and confidence > 0.7:
                print(f"‚ö†Ô∏è Failure detected: {failure_type} "
                      f"(confidence: {confidence:.2f})")
                print("   Attempting recovery...")
                
                # Recovery
                recovery_actions = self.recover(failure_type, robot_state)
                
                if recovery_actions:
                    # Execute recovery
                    for rec_action in recovery_actions:
                        self.execute_action(rec_action)
                    
                    # Wait for stabilization
                    time.sleep(0.5)
                    
                    # Get new observation
                    obs = self.get_observation()
                    
                    # Retry
                    continue
                else:
                    print("   No recovery strategy available")
                    return False
            
            # Success
            return True
        
        print("‚ùå All recovery attempts failed")
        return False

class CollisionDetector:
    """
    Ï∂©Îèå Í∞êÏßÄ
    """
    def __init__(self, robot):
        self.robot = robot
    
    def check(self, robot_state):
        # Check contact forces
        contact_forces = robot_state.get('contact_forces', np.zeros(7))
        
        # Threshold
        threshold = 10.0  # Newtons
        
        return np.any(np.abs(contact_forces) > threshold)

class StuckDetector:
    """
    Stuck Í∞êÏßÄ
    """
    def __init__(self, robot, window=10):
        self.robot = robot
        self.window = window
        self.velocity_history = deque(maxlen=window)
    
    def check(self, robot_state):
        velocity = robot_state.get('joint_velocities', np.zeros(7))
        self.velocity_history.append(np.linalg.norm(velocity))
        
        if len(self.velocity_history) < self.window:
            return False
        
        # Check if velocity is consistently low
        avg_velocity = np.mean(self.velocity_history)
        
        return avg_velocity < 0.01  # Very slow

class GraspDetector:
    """
    Grasp ÏÑ±Í≥µ/Ïã§Ìå® Í∞êÏßÄ
    """
    def __init__(self, robot):
        self.robot = robot
    
    def check_success(self, robot_state):
        """
        Grasp ÏÑ±Í≥µ Ïó¨Î∂Ä
        """
        gripper_state = robot_state.get('gripper_state', 0)
        gripper_force = robot_state.get('gripper_force', 0)
        
        # Gripper closed and force detected
        return gripper_state > 0.8 and gripper_force > 1.0
    
    def check_failure(self, obs, robot_state):
        """
        Grasp Ïã§Ìå® Í∞êÏßÄ
        """
        # Gripper closed but no object detected
        gripper_state = robot_state.get('gripper_state', 0)
        gripper_force = robot_state.get('gripper_force', 0)
        
        return gripper_state > 0.8 and gripper_force < 0.5
```

---

### Week 3-4: Safety Layer
```python
# safety_layer.py

class SafetyLayer:
    """
    Î°úÎ¥á ÏïàÏ†Ñ ÏãúÏä§ÌÖú
    
    Í∏∞Îä•:
    1. Action validation
    2. Joint limit enforcement
    3. Velocity/acceleration limits
    4. Workspace boundaries
    5. Collision prediction
    6. Emergency stop
    """
    
    def __init__(self, robot):
        self.robot = robot
        
        # Limits
        self.joint_limits = robot.get_joint_limits()
        self.velocity_limits = np.array([2.0] * 7)  # rad/s
        self.acceleration_limits = np.array([5.0] * 7)  # rad/s^2
        
        # Workspace boundaries
        self.workspace_bounds = {
            'x': [0.2, 0.8],
            'y': [-0.5, 0.5],
            'z': [0.0, 1.0]
        }
        
        # History for acceleration check
        self.action_history = deque(maxlen=10)
        
        # Statistics
        self.violations = {
            'joint_limits': 0,
            'velocity': 0,
            'acceleration': 0,
            'workspace': 0,
            'singularity': 0
        }
    
    def check_action(self, action, current_state):
        """
        Action ÏïàÏ†ÑÏÑ± Í≤ÄÏ¶ù
        
        Args:
            action: proposed action
            current_state: current robot state
        
        Returns:
            is_safe: bool
            warnings: list of warning strings
        """
        warnings = []
        
        # 1. Joint limits
        predicted_joints = current_state['joint_pos'] + action
        
        if np.any(predicted_joints < self.joint_limits[:, 0]) or \
           np.any(predicted_joints > self.joint_limits[:, 1]):
            warnings.append("Joint limits violated")
            self.violations['joint_limits'] += 1
        
        # 2. Velocity limits (assuming 10Hz control)
        velocity = action / 0.1
        if np.any(np.abs(velocity) > self.velocity_limits):
            warnings.append("Velocity limits violated")
            self.violations['velocity'] += 1
        
        # 3. Acceleration limits
        if len(self.action_history) > 0:
            last_velocity = self.action_history[-1] / 0.1
            acceleration = (velocity - last_velocity) / 0.1
            
            if np.any(np.abs(acceleration) > self.acceleration_limits):
                warnings.append("Acceleration limits violated")
                self.violations['acceleration'] += 1
        
        # 4. Workspace bounds
        ee_pos = self.robot.forward_kinematics(predicted_joints)
        if not self.is_in_workspace(ee_pos):
            warnings.append("Out of workspace")
            self.violations['workspace'] += 1
        
        # 5. Singularity check
        if self.is_near_singularity(predicted_joints):
            warnings.append("Near singularity")
            self.violations['singularity'] += 1
        
        # Record action
        self.action_history.append(action)
        
        is_safe = len(warnings) == 0
        
        return is_safe, warnings
    
    def clip_action(self, action, current_state):
        """
        Unsafe actionÏùÑ safeÌïòÍ≤å ÏàòÏ†ï
        
        Returns:
            clipped_action: modified safe action
        """
        clipped = action.copy()
        
        # 1. Joint limits
        predicted = current_state['joint_pos'] + clipped
        
        # Clip to stay within limits
        clipped = np.clip(
            clipped,
            self.joint_limits[:, 0] - current_state['joint_pos'],
            self.joint_limits[:, 1] - current_state['joint_pos']
        )
        
        # 2. Velocity limits
        max_delta = self.velocity_limits * 0.1  # 10Hz
        clipped = np.clip(clipped, -max_delta, max_delta)
        
        # 3. Acceleration limits
        if len(self.action_history) > 0:
            last_action = self.action_history[-1]
            max_change = self.acceleration_limits * 0.1 * 0.1  # 10Hz, dt^2
            
            delta_action = clipped - last_action
            delta_action = np.clip(delta_action, -max_change, max_change)
            clipped = last_action + delta_action
        
        return clipped
    
    def is_in_workspace(self, position):
        """
        Check if position is in workspace
        """
        x, y, z = position
        
        return (self.workspace_bounds['x'][0] <= x <= self.workspace_bounds['x'][1] and
                self.workspace_bounds['y'][0] <= y <= self.workspace_bounds['y'][1] and
                self.workspace_bounds['z'][0] <= z <= self.workspace_bounds['z'][1])
    
    def is_near_singularity(self, joint_positions):
        """
        Check if configuration is near singularity
        
        Method: Compute Jacobian and check condition number
        """
        jacobian = self.robot.compute_jacobian(joint_positions)
        
        # Compute condition number
        try:
            _, s, _ = np.linalg.svd(jacobian)
            condition_number = s[0] / s[-1] if s[-1] > 1e-10 else float('inf')
            
            # Threshold
            threshold = 100
            
            return condition_number > threshold
        except:
            return False
    
    def emergency_stop(self):
        """
        ÎπÑÏÉÅ Ï†ïÏßÄ
        """
        print("üõë EMERGENCY STOP ACTIVATED")
        
        # Stop all motion
        self.robot.stop()
        
        # Hold position
        self.robot.hold_position()
        
        # Log
        print(f"   Violation history: {self.violations}")
    
    def get_statistics(self):
        """
        Safety statistics
        """
        total = sum(self.violations.values())
        
        print("\n" + "="*60)
        print("SAFETY STATISTICS")
        print("="*60)
        print(f"Total violations: {total}")
        for violation_type, count in self.violations.items():
            percentage = (count / total * 100) if total > 0 else 0
            print(f"  {violation_type:20s}: {count:4d} ({percentage:5.1f}%)")
        print("="*60)

# Predictive Safety
class PredictiveSafety:
    """
    ÏòàÏ∏° Í∏∞Î∞ò ÏïàÏ†Ñ ÏãúÏä§ÌÖú
    
    ÎØ∏Îûò trajectoryÎ•º ÏòàÏ∏°ÌïòÏó¨ Ï∂©Îèå Î∞©ÏßÄ
    """
    
    def __init__(self, robot, env):
        self.robot = robot
        self.env = env
        self.prediction_horizon = 10  # steps
    
    def predict_trajectory(self, current_state, action_sequence):
        """
        Action sequenceÎ°úÎ∂ÄÌÑ∞ trajectory ÏòàÏ∏°
        
        Args:
            current_state: current robot state
            action_sequence: sequence of actions
        
        Returns:
            trajectory: list of predicted states
        """
        trajectory = []
        state = current_state.copy()
        
        for action in action_sequence:
            # Predict next state (using robot dynamics)
            next_state = self.robot.predict_next_state(state, action)
            trajectory.append(next_state)
            state = next_state
        
        return trajectory
    
    def check_collision_free(self, trajectory):
        """
        TrajectoryÍ∞Ä Ï∂©Îèå ÏóÜÎäîÏßÄ ÌôïÏù∏
        
        Args:
            trajectory: list of states
        
        Returns:
            is_safe: bool
            first_collision_step: int or None
        """
        for step, state in enumerate(trajectory):
            # Check collision at this state
            if self.env.check_collision(state):
                return False, step
        
        return True, None
    
    def replan_if_unsafe(self, action_sequence):
        """
        Unsafe trajectoryÎ©¥ re-planning
        
        Args:
            action_sequence: proposed actions
        
        Returns:
            safe_actions: modified safe actions
        """
        current_state = self.robot.get_current_state()
        
        # Predict trajectory
        trajectory = self.predict_trajectory(current_state, action_sequence)
        
        # Check safety
        is_safe, collision_step = self.check_collision_free(trajectory)
        
        if not is_safe:
            print(f"‚ö†Ô∏è Predicted collision at step {collision_step}")
            print("   Re-planning...")
            
            # Truncate unsafe part
            safe_actions = action_sequence[:collision_step]
            
            # Add stop action
            safe_actions.append(np.zeros_like(action_sequence[0]))
            
            return safe_actions
        
        return action_sequence
```

**ÏãúÍ∞Ñ: Ï£º 6-8ÏãúÍ∞Ñ**

### Week 5-6: ROS2 ÏôÑÏ†Ñ ÌÜµÌï©

#### VLA ROS2 Node Íµ¨ÌòÑ
```python
# vla_node.py
import rclpy
from rclpy.node import Node
from rclpy.lifecycle import LifecycleNode, LifecycleState, TransitionCallbackReturn
from rclpy.action import ActionServer
from rclpy.callback_groups import ReentrantCallbackGroup

from sensor_msgs.msg import Image, JointState
from geometry_msgs.msg import PoseStamped
from std_msgs.msg import Bool
from diagnostic_updater import Updater, DiagnosticStatusWrapper
from tf2_ros import TransformBroadcaster, Buffer, TransformListener

import torch
import numpy as np
from cv_bridge import CvBridge

class VLALifecycleNode(LifecycleNode):
    """
    VLA Lifecycle Node
    
    ROS2 Lifecycle Ìå®ÌÑ¥ ÌôúÏö©:
    - Unconfigured ‚Üí Configuring ‚Üí Inactive
    - Inactive ‚Üí Activating ‚Üí Active
    - Active ‚Üí Deactivating ‚Üí Inactive
    - Cleanup, Shutdown
    
    ROS2 Í≤ΩÌóò ÌôúÏö©!
    """
    
    def __init__(self):
        super().__init__('vla_node')
        
        # Parameters
        self.declare_parameter('model_path', '')
        self.declare_parameter('device', 'cuda')
        self.declare_parameter('control_frequency', 10.0)
        self.declare_parameter('action_chunk_size', 10)
        
        # State
        self.model = None
        self.latest_image = None
        self.latest_joint_state = None
        self.action_buffer = []
        
        # CV Bridge
        self.bridge = CvBridge()
        
        # Diagnostics
        self.diagnostics = None
        
        self.get_logger().info('VLA Node created')
    
    def on_configure(self, state: LifecycleState) -> TransitionCallbackReturn:
        """
        Configure state: Setup resources
        """
        self.get_logger().info('Configuring VLA Node...')
        
        # Get parameters
        model_path = self.get_parameter('model_path').value
        device = self.get_parameter('device').value
        self.control_freq = self.get_parameter('control_frequency').value
        
        # Load VLA model
        try:
            self.model = self.load_model(model_path, device)
            self.get_logger().info(f'Model loaded from {model_path}')
        except Exception as e:
            self.get_logger().error(f'Failed to load model: {e}')
            return TransitionCallbackReturn.FAILURE
        
        # Create callback group (for parallel callbacks)
        self.callback_group = ReentrantCallbackGroup()
        
        # Publishers
        self.joint_cmd_pub = self.create_lifecycle_publisher(
            JointState,
            '/joint_commands',
            10
        )
        
        self.status_pub = self.create_lifecycle_publisher(
            Bool,
            '/vla/status',
            10
        )
        
        # Subscribers
        self.image_sub = self.create_subscription(
            Image,
            '/camera/image_raw',
            self.image_callback,
            10,
            callback_group=self.callback_group
        )
        
        self.joint_state_sub = self.create_subscription(
            JointState,
            '/joint_states',
            self.joint_state_callback,
            10,
            callback_group=self.callback_group
        )
        
        # TF2
        self.tf_buffer = Buffer()
        self.tf_listener = TransformListener(self.tf_buffer, self)
        self.tf_broadcaster = TransformBroadcaster(self)
        
        # Diagnostics
        self.diagnostics = Updater(self)
        self.diagnostics.setHardwareID('VLA-Robot')
        self.diagnostics.add('VLA Status', self.diagnostic_callback)
        
        # Safety layer
        from safety_layer import SafetyLayer
        self.safety = SafetyLayer(robot=None)  # Initialize with actual robot
        
        # Failure recovery
        from failure_recovery import FailureRecovery
        self.recovery = FailureRecovery(policy=self.model, robot=None)
        
        self.get_logger().info('Configuration complete')
        return TransitionCallbackReturn.SUCCESS
    
    def on_activate(self, state: LifecycleState) -> TransitionCallbackReturn:
        """
        Activate state: Start operations
        """
        self.get_logger().info('Activating VLA Node...')
        
        # Activate publishers
        self.joint_cmd_pub.on_activate()
        self.status_pub.on_activate()
        
        # Start control loop
        self.control_timer = self.create_timer(
            1.0 / self.control_freq,
            self.control_loop,
            callback_group=self.callback_group
        )
        
        # Start diagnostics
        self.diag_timer = self.create_timer(
            1.0,
            lambda: self.diagnostics.update()
        )
        
        self.get_logger().info('VLA Node activated')
        return TransitionCallbackReturn.SUCCESS
    
    def on_deactivate(self, state: LifecycleState) -> TransitionCallbackReturn:
        """
        Deactivate state: Stop operations
        """
        self.get_logger().info('Deactivating VLA Node...')
        
        # Stop control loop
        self.control_timer.cancel()
        self.diag_timer.cancel()
        
        # Deactivate publishers
        self.joint_cmd_pub.on_deactivate()
        self.status_pub.on_deactivate()
        
        # Clear action buffer
        self.action_buffer = []
        
        self.get_logger().info('VLA Node deactivated')
        return TransitionCallbackReturn.SUCCESS
    
    def on_cleanup(self, state: LifecycleState) -> TransitionCallbackReturn:
        """
        Cleanup state: Release resources
        """
        self.get_logger().info('Cleaning up VLA Node...')
        
        # Destroy publishers/subscribers
        self.destroy_publisher(self.joint_cmd_pub)
        self.destroy_publisher(self.status_pub)
        self.destroy_subscription(self.image_sub)
        self.destroy_subscription(self.joint_state_sub)
        
        # Unload model
        self.model = None
        
        self.get_logger().info('Cleanup complete')
        return TransitionCallbackReturn.SUCCESS
    
    def on_shutdown(self, state: LifecycleState) -> TransitionCallbackReturn:
        """
        Shutdown state
        """
        self.get_logger().info('Shutting down VLA Node...')
        return TransitionCallbackReturn.SUCCESS
    
    def image_callback(self, msg):
        """
        Camera image callback
        """
        try:
            # Convert ROS Image to numpy
            cv_image = self.bridge.imgmsg_to_cv2(msg, desired_encoding='rgb8')
            self.latest_image = cv_image
        except Exception as e:
            self.get_logger().error(f'Image conversion failed: {e}')
    
    def joint_state_callback(self, msg):
        """
        Joint state callback
        """
        self.latest_joint_state = msg
    
    def control_loop(self):
        """
        Main control loop (10Hz)
        """
        # Check if data available
        if self.latest_image is None or self.latest_joint_state is None:
            return
        
        # Prepare observation
        obs = self.prepare_observation()
        
        # Get action (with chunking)
        if len(self.action_buffer) == 0:
            # Predict new action chunk
            with torch.no_grad():
                action_chunk = self.model.predict(obs)
                self.action_buffer = list(action_chunk.cpu().numpy())
        
        # Pop next action
        action = self.action_buffer.pop(0)
        
        # Safety check
        current_state = {
            'joint_pos': np.array(self.latest_joint_state.position),
            'joint_vel': np.array(self.latest_joint_state.velocity),
        }
        
        is_safe, warnings = self.safety.check_action(action, current_state)
        
        if not is_safe:
            self.get_logger().warn(f'Unsafe action detected: {warnings}')
            action = self.safety.clip_action(action, current_state)
        
        # Publish command
        self.publish_joint_command(action)
        
        # Update status
        status_msg = Bool()
        status_msg.data = True
        self.status_pub.publish(status_msg)
    
    def prepare_observation(self):
        """
        Prepare observation for model
        """
        # Preprocess image
        from torchvision import transforms
        
        transform = transforms.Compose([
            transforms.ToTensor(),
            transforms.Resize((224, 224)),
            transforms.Normalize(
                mean=[0.485, 0.456, 0.406],
                std=[0.229, 0.224, 0.225]
            )
        ])
        
        image_tensor = transform(self.latest_image).unsqueeze(0)
        
        # Proprioception
        joint_pos = torch.FloatTensor(self.latest_joint_state.position).unsqueeze(0)
        joint_vel = torch.FloatTensor(self.latest_joint_state.velocity).unsqueeze(0)
        
        # Combine
        proprio = torch.cat([joint_pos, joint_vel], dim=-1)
        
        obs = {
            'rgb': image_tensor.to(self.model.device),
            'proprio': proprio.to(self.model.device)
        }
        
        return obs
    
    def publish_joint_command(self, action):
        """
        Publish joint command
        """
        cmd_msg = JointState()
        cmd_msg.header.stamp = self.get_clock().now().to_msg()
        cmd_msg.name = self.latest_joint_state.name
        
        # Convert delta to absolute positions
        current_pos = np.array(self.latest_joint_state.position)
        target_pos = current_pos + action
        
        cmd_msg.position = target_pos.tolist()
        
        self.joint_cmd_pub.publish(cmd_msg)
    
    def diagnostic_callback(self, stat: DiagnosticStatusWrapper):
        """
        Diagnostics updater callback
        """
        # Overall status
        if self.latest_image is not None and self.latest_joint_state is not None:
            stat.summary(DiagnosticStatusWrapper.OK, "VLA operational")
        else:
            stat.summary(DiagnosticStatusWrapper.WARN, "Waiting for data")
        
        # Add diagnostic info
        stat.add("Image received", str(self.latest_image is not None))
        stat.add("Joint state received", str(self.latest_joint_state is not None))
        stat.add("Action buffer size", str(len(self.action_buffer)))
        stat.add("Model device", str(self.model.device if self.model else "None"))
        
        # Safety statistics
        if hasattr(self.safety, 'violations'):
            for key, val in self.safety.violations.items():
                stat.add(f"Safety/{key}", str(val))
        
        return stat
    
    def load_model(self, model_path, device):
        """
        Load VLA model
        """
        from act_model import ACTPolicy
        
        checkpoint = torch.load(model_path, map_location=device)
        
        model = ACTPolicy(checkpoint['config'])
        model.load_state_dict(checkpoint['model_state_dict'])
        model.to(device)
        model.eval()
        
        return model

def main(args=None):
    rclpy.init(args=args)
    
    node = VLALifecycleNode()
    
    # Executor with multiple threads
    from rclpy.executors import MultiThreadedExecutor
    executor = MultiThreadedExecutor()
    executor.add_node(node)
    
    try:
        executor.spin()
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()
```

---

#### Launch ÌååÏùº
```python
# vla_bringup.launch.py
from launch import LaunchDescription
from launch.actions import DeclareLaunchArgument, EmitEvent, RegisterEventHandler
from launch.conditions import IfCondition
from launch.events import matches_action
from launch.substitutions import LaunchConfiguration, PathJoinSubstitution
from launch_ros.actions import LifecycleNode, Node
from launch_ros.events.lifecycle import ChangeState
from launch_ros.event_handlers import OnStateTransition
from lifecycle_msgs.msg import Transition

def generate_launch_description():
    # Declare arguments
    model_path_arg = DeclareLaunchArgument(
        'model_path',
        default_value='/path/to/model.pt',
        description='Path to VLA model checkpoint'
    )
    
    device_arg = DeclareLaunchArgument(
        'device',
        default_value='cuda',
        description='Device for model inference'
    )
    
    use_sim_arg = DeclareLaunchArgument(
        'use_sim',
        default_value='true',
        description='Use simulation'
    )
    
    # VLA Node (Lifecycle)
    vla_node = LifecycleNode(
        package='vla_control',
        executable='vla_node',
        name='vla_node',
        namespace='',
        parameters=[{
            'model_path': LaunchConfiguration('model_path'),
            'device': LaunchConfiguration('device'),
            'control_frequency': 10.0,
            'action_chunk_size': 10
        }],
        output='screen'
    )
    
    # Camera Node (if simulation)
    camera_node = Node(
        package='isaac_ros_visual_slam',
        executable='isaac_ros_visual_slam',
        name='camera',
        condition=IfCondition(LaunchConfiguration('use_sim')),
        output='screen'
    )
    
    # Robot State Publisher
    robot_state_publisher = Node(
        package='robot_state_publisher',
        executable='robot_state_publisher',
        name='robot_state_publisher',
        parameters=[{'robot_description': 'robot.urdf'}],
        output='screen'
    )
    
    # Lifecycle transitions
    # Configure
    configure_event = EmitEvent(
        event=ChangeState(
            lifecycle_node_matcher=matches_action(vla_node),
            transition_id=Transition.TRANSITION_CONFIGURE
        )
    )
    
    # Activate after configured
    activate_event = RegisterEventHandler(
        OnStateTransition(
            target_lifecycle_node=vla_node,
            goal_state='inactive',
            entities=[
                EmitEvent(
                    event=ChangeState(
                        lifecycle_node_matcher=matches_action(vla_node),
                        transition_id=Transition.TRANSITION_ACTIVATE
                    )
                )
            ]
        )
    )
    
    return LaunchDescription([
        model_path_arg,
        device_arg,
        use_sim_arg,
        vla_node,
        camera_node,
        robot_state_publisher,
        configure_event,
        activate_event
    ])
```

---

#### Integration with Navigation (Nav2)
```python
# vla_nav_integration.py
from nav2_simple_commander.robot_navigator import BasicNavigator
from geometry_msgs.msg import PoseStamped
import rclpy

class VLANavigationIntegration:
    """
    VLA + Nav2 ÌÜµÌï©
    
    ÏãúÎÇòÎ¶¨Ïò§:
    1. Nav2Î°ú Î™©Ìëú ÏúÑÏπòÍπåÏßÄ Ïù¥Îèô
    2. VLAÎ°ú manipulation ÏàòÌñâ
    3. Îã§Ïùå Î™©ÌëúÎ°ú Ïù¥Îèô
    """
    
    def __init__(self):
        rclpy.init()
        
        # Nav2 navigator
        self.navigator = BasicNavigator()
        
        # VLA client
        self.vla_client = VLAActionClient()
        
        # Wait for navigation to be ready
        self.navigator.waitUntilNav2Active()
    
    def execute_pick_and_place_task(self, waypoints):
        """
        Complete pick and place task
        
        Args:
            waypoints: list of (nav_pose, manipulation_task)
        """
        for nav_pose, task in waypoints:
            print(f"\n{'='*60}")
            print(f"Waypoint: {task['name']}")
            print(f"{'='*60}")
            
            # 1. Navigate to pose
            print("Step 1: Navigating to target...")
            self.navigate_to_pose(nav_pose)
            
            # 2. Execute manipulation
            print("Step 2: Executing manipulation...")
            success = self.execute_manipulation(task)
            
            if not success:
                print(f"‚ùå Manipulation failed at {task['name']}")
                return False
            
            print(f"‚úÖ Completed {task['name']}")
        
        print("\nüéâ All tasks completed!")
        return True
    
    def navigate_to_pose(self, pose: PoseStamped):
        """
        Navigate to target pose using Nav2
        """
        self.navigator.goToPose(pose)
        
        # Wait for navigation to complete
        while not self.navigator.isTaskComplete():
            feedback = self.navigator.getFeedback()
            
            # Print progress
            if feedback:
                print(f"  Distance remaining: {feedback.distance_remaining:.2f}m")
            
            rclpy.spin_once(self.navigator, timeout_sec=0.1)
        
        result = self.navigator.getResult()
        
        if result == TaskResult.SUCCEEDED:
            print("  ‚úÖ Navigation succeeded")
            return True
        else:
            print(f"  ‚ùå Navigation failed: {result}")
            return False
    
    def execute_manipulation(self, task):
        """
        Execute manipulation using VLA
        """
        # Send goal to VLA action server
        goal = VLAGoal()
        goal.task_type = task['type']  # 'pick' or 'place'
        goal.target_object = task.get('object', '')
        
        future = self.vla_client.send_goal_async(goal)
        rclpy.spin_until_future_complete(self.vla_client, future)
        
        goal_handle = future.result()
        
        if not goal_handle.accepted:
            print("  ‚ùå VLA goal rejected")
            return False
        
        # Wait for result
        result_future = goal_handle.get_result_async()
        rclpy.spin_until_future_complete(self.vla_client, result_future)
        
        result = result_future.result().result
        
        return result.success

# Usage
def main():
    integration = VLANavigationIntegration()
    
    # Define waypoints
    waypoints = [
        (create_pose(x=1.0, y=0.0), {'name': 'Shelf A', 'type': 'pick', 'object': 'box_1'}),
        (create_pose(x=3.0, y=2.0), {'name': 'Pallet B', 'type': 'place'}),
        (create_pose(x=1.0, y=0.0), {'name': 'Shelf A', 'type': 'pick', 'object': 'box_2'}),
        (create_pose(x=3.0, y=2.0), {'name': 'Pallet B', 'type': 'place'}),
    ]
    
    # Execute
    integration.execute_pick_and_place_task(waypoints)

def create_pose(x, y, theta=0.0):
    """
    Helper function to create PoseStamped
    """
    pose = PoseStamped()
    pose.header.frame_id = 'map'
    pose.pose.position.x = x
    pose.pose.position.y = y
    
    # Quaternion from yaw
    from tf_transformations import quaternion_from_euler
    q = quaternion_from_euler(0, 0, theta)
    pose.pose.orientation.x = q[0]
    pose.pose.orientation.y = q[1]
    pose.pose.orientation.z = q[2]
    pose.pose.orientation.w = q[3]
    
    return pose
```

---

#### ROS2 Action Server
```python
# vla_action_server.py
import rclpy
from rclpy.action import ActionServer
from rclpy.node import Node

from vla_interfaces.action import VLAManipulation

class VLAActionServer(Node):
    """
    VLA Action Server
    
    Action definition (vla_interfaces/action/VLAManipulation.action):
    
    # Goal
    string task_type  # 'pick', 'place', 'move'
    string target_object
    geometry_msgs/Pose target_pose
    ---
    # Result
    bool success
    string message
    ---
    # Feedback
    float32 progress
    string current_phase
    """
    
    def __init__(self, vla_model):
        super().__init__('vla_action_server')
        
        self.vla_model = vla_model
        
        self._action_server = ActionServer(
            self,
            VLAManipulation,
            'vla_manipulation',
            self.execute_callback
        )
        
        self.get_logger().info('VLA Action Server started')
    
    def execute_callback(self, goal_handle):
        """
        Execute action callback
        """
        self.get_logger().info('Executing VLA manipulation...')
        
        # Get goal
        goal = goal_handle.request
        
        # Feedback
        feedback_msg = VLAManipulation.Feedback()
        
        # Execute task
        try:
            if goal.task_type == 'pick':
                success = self.execute_pick(goal, goal_handle, feedback_msg)
            elif goal.task_type == 'place':
                success = self.execute_place(goal, goal_handle, feedback_msg)
            else:
                success = False
                self.get_logger().error(f'Unknown task type: {goal.task_type}')
        
        except Exception as e:
            self.get_logger().error(f'Execution failed: {e}')
            success = False
        
        # Result
        goal_handle.succeed()
        
        result = VLAManipulation.Result()
        result.success = success
        result.message = 'Success' if success else 'Failed'
        
        return result
    
    def execute_pick(self, goal, goal_handle, feedback_msg):
        """
        Execute pick task
        """
        phases = ['approaching', 'grasping', 'lifting', 'retracting']
        
        for i, phase in enumerate(phases):
            # Update feedback
            feedback_msg.current_phase = phase
            feedback_msg.progress = (i + 1) / len(phases)
            goal_handle.publish_feedback(feedback_msg)
            
            self.get_logger().info(f'Phase: {phase}')
            
            # Execute phase with VLA
            success = self.execute_phase(phase)
            
            if not success:
                return False
        
        return True
    
    def execute_phase(self, phase):
        """
        Execute single phase using VLA
        """
        # Get observations
        obs = self.get_observation()
        
        # VLA inference
        with torch.no_grad():
            actions = self.vla_model.predict(obs)
        
        # Execute actions
        for action in actions:
            self.execute_action(action)
            
            # Check for failure
            if self.check_failure():
                return False
        
        return True
```

**ÏãúÍ∞Ñ: Ï£º 8-10ÏãúÍ∞Ñ**

---

### Week 7-8: Sim-to-Real Transfer Ï§ÄÎπÑ

#### Domain Randomization Í∞ïÌôî
```python
# advanced_domain_randomization.py

class AdvancedDomainRandomizer:
    """
    Í≥†Í∏â Domain Randomization
    
    Î™©Ï†Å: Sim-to-Real gap ÏµúÏÜåÌôî
    
    Ï†ÑÎûµ:
    1. Physics randomization
    2. Visual randomization
    3. Sensor noise
    4. Actuation noise
    5. Dynamics randomization
    """
    
    def __init__(self, world, config):
        self.world = world
        self.config = config
        
        # Randomization ranges
        self.ranges = {
            'gravity': [-10.5, -9.5],
            'friction': [0.3, 1.5],
            'mass': [0.8, 1.2],  # multiplier
            'lighting_intensity': [2000, 8000],
            'color_temperature': [3000, 7000],
            'camera_noise': [0, 0.05],
            'actuator_noise': [0, 0.02],
        }
    
    def randomize_all(self):
        """
        Randomize all aspects
        """
        self.randomize_physics()
        self.randomize_visuals()
        self.randomize_sensors()
        self.randomize_dynamics()
    
    def randomize_physics(self):
        """
        Î¨ºÎ¶¨ ÌååÎùºÎØ∏ÌÑ∞ ÎûúÎç§Ìôî
        """
        # Gravity
        gravity_z = np.random.uniform(*self.ranges['gravity'])
        self.world.set_gravity([0, 0, gravity_z])
        
        # Global friction multiplier
        friction_mult = np.random.uniform(*self.ranges['friction'])
        
        # Apply to all objects
        for obj in self.world.scene.get_all_objects():
            if hasattr(obj, 'get_applied_physics_material'):
                material = obj.get_applied_physics_material()
                
                if material:
                    base_static = material.get_static_friction()
                    base_dynamic = material.get_dynamic_friction()
                    
                    material.set_static_friction(base_static * friction_mult)
                    material.set_dynamic_friction(base_dynamic * friction_mult)
        
        # Mass variation
        mass_mult = np.random.uniform(*self.ranges['mass'])
        
        for obj in self.world.scene.get_all_objects():
            if hasattr(obj, 'get_mass'):
                base_mass = obj.get_mass()
                obj.set_mass(base_mass * mass_mult)
        
        # Restitution (bounciness)
        for obj in self.world.scene.get_all_objects():
            if hasattr(obj, 'get_applied_physics_material'):
                material = obj.get_applied_physics_material()
                
                if material:
                    restitution = np.random.uniform(0, 0.5)
                    material.set_restitution(restitution)
    
    def randomize_visuals(self):
        """
        ÏãúÍ∞ÅÏ†Å ÏöîÏÜå ÎûúÎç§Ìôî
        """
        # Lighting
        from pxr import UsdLux
        stage = omni.usd.get_context().get_stage()
        
        for i in range(4):
            light_path = f"/World/Light_{i}"
            light_prim = stage.GetPrimAtPath(light_path)
            
            if light_prim:
                light = UsdLux.RectLight(light_prim)
                
                # Intensity
                intensity = np.random.uniform(*self.ranges['lighting_intensity'])
                light.GetIntensityAttr().Set(intensity)
                
                # Color temperature
                temp = np.random.uniform(*self.ranges['color_temperature'])
                light.GetColorTemperatureAttr().Set(temp)
                
                # Position variation
                current_pos = light.GetPrim().GetAttribute('xformOp:translate').Get()
                pos_noise = np.random.uniform(-0.5, 0.5, 3)
                new_pos = tuple(np.array(current_pos) + pos_noise)
                light.GetPrim().GetAttribute('xformOp:translate').Set(new_pos)
        
        # Textures and colors
        for obj in self.world.scene.get_all_objects():
            if hasattr(obj, 'set_color'):
                # Random color in HSV space
                hue = np.random.uniform(0, 1)
                saturation = np.random.uniform(0.3, 1.0)
                value = np.random.uniform(0.4, 1.0)
                
                import colorsys
                rgb = colorsys.hsv_to_rgb(hue, saturation, value)
                obj.set_color(rgb)
        
        # Background
        # Add random patterns or textures to floor/walls
        self.randomize_background()
    
    def randomize_sensors(self):
        """
        ÏÑºÏÑú ÎÖ∏Ïù¥Ï¶à ÎûúÎç§Ìôî
        """
        # Camera noise will be added during observation
        self.camera_noise_std = np.random.uniform(*self.ranges['camera_noise'])
        
        # Camera parameters
        if hasattr(self, 'camera'):
            # Exposure
            exposure = np.random.uniform(0.8, 1.2)
            
            # Gain
            gain = np.random.uniform(0.9, 1.1)
            
            # Apply (implementation dependent on camera API)
    
    def randomize_dynamics(self):
        """
        ÎèôÏó≠Ìïô ÎûúÎç§Ìôî
        """
        # Joint damping
        for joint_idx in range(7):
            damping = np.random.uniform(0.5, 2.0)
            # Set joint damping (implementation dependent)
        
        # Motor characteristics
        # Backlash, delay, etc.
    
    def add_sensor_noise(self, observation):
        """
        Í¥ÄÏ∏°Ïóê ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞Ä (Ïã§ÏãúÍ∞Ñ)
        """
        obs = observation.copy()
        
        # Image noise
        if 'rgb' in obs:
            # Gaussian noise
            noise = np.random.normal(0, self.camera_noise_std * 255, obs['rgb'].shape)
            obs['rgb'] = np.clip(obs['rgb'] + noise, 0, 255).astype(np.uint8)
            
            # Salt and pepper noise
            if np.random.random() < 0.1:
                mask = np.random.random(obs['rgb'].shape[:2]) < 0.01
                obs['rgb'][mask] = np.random.choice([0, 255])
        
        # Depth noise
        if 'depth' in obs:
            depth_noise = np.random.normal(0, 0.01, obs['depth'].shape)
            obs['depth'] = np.clip(obs['depth'] + depth_noise, 0, 5.0)
        
        # Proprioception noise
        if 'joint_pos' in obs:
            joint_noise = np.random.normal(0, 0.01, obs['joint_pos'].shape)
            obs['joint_pos'] += joint_noise
        
        if 'joint_vel' in obs:
            vel_noise = np.random.normal(0, 0.05, obs['joint_vel'].shape)
            obs['joint_vel'] += vel_noise
        
        return obs
    
    def add_actuation_noise(self, action):
        """
        Ïï°Ï∏ÑÏóêÏù¥ÏÖò ÎÖ∏Ïù¥Ï¶à Ï∂îÍ∞Ä
        """
        noise_std = np.random.uniform(*self.ranges['actuator_noise'])
        noise = np.random.normal(0, noise_std, action.shape)
        
        noisy_action = action + noise
        
        # Add delay (random)
        if np.random.random() < 0.1:
            # 10% chance of 1-step delay
            # Store action for next timestep
            pass
        
        return noisy_action
    
    def randomize_background(self):
        """
        Î∞∞Í≤Ω ÎûúÎç§Ìôî
        """
        # Add random objects to background
        num_objects = np.random.randint(0, 5)
        
        for i in range(num_objects):
            # Random position (background)
            position = [
                np.random.uniform(-5, 5),
                np.random.uniform(5, 10),  # Far from robot
                np.random.uniform(0, 2)
            ]
            
            # Random shape
            shape_type = np.random.choice(['cube', 'sphere', 'cylinder'])
            
            # Add to scene
            # Implementation depends on Isaac Sim API

# Curriculum learning for domain randomization
class CurriculumDomainRandomization:
    """
    Ï†êÏßÑÏ†Å ÎÇúÏù¥ÎèÑ Ï¶ùÍ∞Ä
    
    Ï¥àÍ∏∞: ÏïΩÌïú randomization (ÌïôÏäµ Ïö©Ïù¥)
    ÌõÑÎ∞ò: Í∞ïÌïú randomization (robust)
    """
    
    def __init__(self, randomizer, curriculum_steps=10):
        self.randomizer = randomizer
        self.curriculum_steps = curriculum_steps
        self.current_step = 0
    
    def get_randomization_strength(self):
        """
        ÌòÑÏû¨ curriculum stepÏóê Îî∞Î•∏ randomization Í∞ïÎèÑ
        """
        progress = self.current_step / self.curriculum_steps
        
        # Exponential increase
        strength = progress ** 2
        
        return min(strength, 1.0)
    
    def randomize(self):
        """
        CurriculumÏóê Îî∞Î•∏ randomization
        """
        strength = self.get_randomization_strength()
        
        # Scale randomization ranges
        for key in self.randomizer.ranges:
            base_range = self.randomizer.ranges[key]
            
            # Center value
            center = (base_range[0] + base_range[1]) / 2
            
            # Scaled range
            half_width = (base_range[1] - base_range[0]) / 2 * strength
            
            scaled_range = [center - half_width, center + half_width]
            
            # Temporarily update
            original_range = self.randomizer.ranges[key]
            self.randomizer.ranges[key] = scaled_range
        
        # Apply randomization
        self.randomizer.randomize_all()
        
        # Restore original ranges
        # (or keep for next time)
    
    def step_curriculum(self):
        """
        Advance curriculum
        """
        self.current_step += 1
        
        if self.current_step > self.curriculum_steps:
            self.current_step = self.curriculum_steps
        
        print(f"Curriculum step: {self.current_step}/{self.curriculum_steps} "
              f"(strength: {self.get_randomization_strength():.2f})")
```

---

#### Reality Gap Î∂ÑÏÑù
```python
# reality_gap_analysis.py

class RealityGapAnalyzer:
    """
    Sim-Real Gap Î∂ÑÏÑù
    
    ÎπÑÍµê Ìï≠Î™©:
    1. Physics (dynamics, friction, contact)
    2. Perception (lighting, camera, colors)
    3. Actuation (delays, backlash, errors)
    4. Environment (objects, layout)
    """
    
    def __init__(self):
        self.sim_data = []
        self.real_data = []
    
    def collect_sim_data(self, num_episodes=50):
        """
        Simulation Îç∞Ïù¥ÌÑ∞ ÏàòÏßë
        """
        print("Collecting simulation data...")
        
        for ep in range(num_episodes):
            episode_data = self.run_episode_in_sim()
            self.sim_data.append(episode_data)
        
        print(f"Collected {len(self.sim_data)} simulation episodes")
    
    def collect_real_data(self, num_episodes=50):
        """
        Real robot Îç∞Ïù¥ÌÑ∞ ÏàòÏßë
        """
        print("Collecting real robot data...")
        
        for ep in range(num_episodes):
            episode_data = self.run_episode_on_real()
            self.real_data.append(episode_data)
        
        print(f"Collected {len(self.real_data)} real episodes")
    
    def analyze_gap(self):
        """
        Gap Î∂ÑÏÑù Î∞è ÏãúÍ∞ÅÌôî
        """
        print("\n" + "="*60)
        print("REALITY GAP ANALYSIS")
        print("="*60)
        
        # 1. Success rate gap
        sim_success = np.mean([ep['success'] for ep in self.sim_data])
        real_success = np.mean([ep['success'] for ep in self.real_data])
        
        print(f"\nSuccess Rate:")
        print(f"  Simulation: {sim_success*100:.1f}%")
        print(f"  Real:       {real_success*100:.1f}%")
        print(f"  Gap:        {(sim_success - real_success)*100:+.1f}%")
        
        # 2. Trajectory comparison
        self.analyze_trajectory_gap()
        
        # 3. Timing comparison
        self.analyze_timing_gap()
        
        # 4. Perception comparison
        self.analyze_perception_gap()
        
        # 5. Recommendations
        self.generate_recommendations()
    
    def analyze_trajectory_gap(self):
        """
        Trajectory Ï∞®Ïù¥ Î∂ÑÏÑù
        """
        print(f"\nTrajectory Gap:")
        
        # Extract trajectories
        sim_trajs = [ep['trajectory'] for ep in self.sim_data if ep['success']]
        real_trajs = [ep['trajectory'] for ep in self.real_data if ep['success']]
        
        # Compare smoothness
        sim_smoothness = [self.compute_smoothness(t) for t in sim_trajs]
        real_smoothness = [self.compute_smoothness(t) for t in real_trajs]
        
        print(f"  Sim smoothness:  {np.mean(sim_smoothness):.4f}")
        print(f"  Real smoothness: {np.mean(real_smoothness):.4f}")
        
        # Compare path length
        sim_lengths = [self.compute_path_length(t) for t in sim_trajs]
        real_lengths = [self.compute_path_length(t) for t in real_trajs]
        
        print(f"  Sim path length:  {np.mean(sim_lengths):.2f}m")
        print(f"  Real path length: {np.mean(real_lengths):.2f}m")
    
    def analyze_timing_gap(self):
        """
        Timing Ï∞®Ïù¥ Î∂ÑÏÑù
        """
        print(f"\nTiming Gap:")
        
        sim_times = [ep['completion_time'] for ep in self.sim_data if ep['success']]
        real_times = [ep['completion_time'] for ep in self.real_data if ep['success']]
        
        print(f"  Sim time:  {np.mean(sim_times):.2f}s (¬±{np.std(sim_times):.2f})")
        print(f"  Real time: {np.mean(real_times):.2f}s (¬±{np.std(real_times):.2f})")
        
        # Time distribution comparison
        import matplotlib.pyplot as plt
        
        plt.figure(figsize=(10, 6))
        plt.hist(sim_times, bins=20, alpha=0.5, label='Simulation')
        plt.hist(real_times, bins=20, alpha=0.5, label='Real')
        plt.xlabel('Completion Time (s)')
        plt.ylabel('Frequency')
        plt.title('Timing Distribution: Sim vs Real')
        plt.legend()
        plt.savefig('timing_gap.png')
        plt.show()
    
    def analyze_perception_gap(self):
        """
        Perception Ï∞®Ïù¥ Î∂ÑÏÑù
        """
        print(f"\nPerception Gap:")
        
        # Compare image statistics
        sim_images = [ep['images'] for ep in self.sim_data]
        real_images = [ep['images'] for ep in self.real_data]
        
        # Brightness
        sim_brightness = [np.mean(img) for imgs in sim_images for img in imgs]
        real_brightness = [np.mean(img) for imgs in real_images for img in imgs]
        
        print(f"  Sim brightness:  {np.mean(sim_brightness):.1f}")
        print(f"  Real brightness: {np.mean(real_brightness):.1f}")
        
        # Contrast
        sim_contrast = [np.std(img) for imgs in sim_images for img in imgs]
        real_contrast = [np.std(img) for imgs in real_images for img in imgs]
        
        print(f"  Sim contrast:  {np.mean(sim_contrast):.1f}")
        print(f"  Real contrast: {np.mean(real_contrast):.1f}")
    
    def generate_recommendations(self):
        """
        Í∞úÏÑ† Í∂åÏû•ÏÇ¨Ìï≠
        """
        print("\n" + "="*60)
        print("RECOMMENDATIONS")
        print("="*60)
        
        sim_success = np.mean([ep['success'] for ep in self.sim_data])
        real_success = np.mean([ep['success'] for ep in self.real_data])
        
        gap = sim_success - real_success
        
        if gap > 0.2:  # 20% gap
            print("\n‚ö†Ô∏è Large sim-real gap detected!")
            print("\nPriority actions:")
            print("1. Increase domain randomization strength")
            print("2. Collect more diverse simulation data")
            print("3. Fine-tune on real robot data")
            print("4. Check calibration (camera, robot)")
        
        elif gap > 0.1:  # 10% gap
            print("\n‚ö†Ô∏è Moderate sim-real gap")
            print("\nSuggested actions:")
            print("1. Add more visual randomization")
            print("2. Tune physics parameters to match real")
            print("3. Add sensor noise modeling")
        
        else:
            print("\n‚úÖ Small sim-real gap")
            print("\nMaintain current approach:")
            print("1. Continue domain randomization")
            print("2. Monitor performance over time")
            print("3. Occasional real data collection")
    
    def compute_smoothness(self, trajectory):
        """
        Trajectory smoothness (jerk)
        """
        positions = np.array([state['joint_pos'] for state in trajectory])
        velocities = np.diff(positions, axis=0)
        jerks = np.diff(velocities, axis=0)
        
        return -np.mean(np.abs(jerks))
    
    def compute_path_length(self, trajectory):
        """
        Total path length
        """
        positions = np.array([state['ee_pos'] for state in trajectory])
        diffs = np.diff(positions, axis=0)
        distances = np.linalg.norm(diffs, axis=1)
        
        return np.sum(distances)
```

---

#### Ïã§Ï†ú Î°úÎ¥á Î∞∞Ìè¨ Ï≤¥ÌÅ¨Î¶¨Ïä§Ìä∏
```markdown
## Real Robot Deployment Checklist

### Pre-deployment (Simulation)

#### Model Validation
- [ ] Model achieves >70% success in simulation
- [ ] Model robust to domain randomization
- [ ] Action smoothness acceptable
- [ ] No safety violations in 100+ episodes
- [ ] Tested with various box sizes/positions

#### Safety Verification
- [ ] Safety layer tested and verified
- [ ] Emergency stop functional
- [ ] Joint limits enforced
- [ ] Velocity limits enforced
- [ ] Workspace boundaries defined
- [ ] Collision detection working

#### Code Quality
- [ ] Code reviewed and tested
- [ ] No hardcoded paths or parameters
- [ ] Proper error handling
- [ ] Logging implemented
- [ ] ROS2 integration tested

---

### Hardware Setup

#### Robot Calibration
- [ ] Robot zeroed and homed
- [ ] Joint encoders calibrated
- [ ] Tool center point (TCP) calibrated
- [ ] Gripper calibrated
- [ ] Force/torque sensor calibrated (if applicable)

#### Camera Setup
- [ ] Camera mounted securely
- [ ] Camera calibrated (intrinsics)
- [ ] Camera-robot calibration (extrinsics)
- [ ] Lighting consistent with training
- [ ] Frame rate stable (20Hz)
- [ ] Image quality verified

#### Workspace Preparation
- [ ] Workspace clear of obstacles
- [ ] Safety barriers in place
- [ ] Emergency stop accessible
- [ ] Lighting controlled
- [ ] Floor markers for repeatability

---

### Initial Testing

#### Sanity Checks
- [ ] Camera feed visible in ROS2
- [ ] Joint states publishing correctly
- [ ] Commands being received
- [ ] TF tree correct
- [ ] No network delays

#### Manual Control
- [ ] Manually move robot through workspace
- [ ] Test gripper open/close
- [ ] Verify safety stops work
- [ ] Check for mechanical issues
- [ ] Confirm smooth motion

#### Dry Run (No Objects)
- [ ] Run VLA with empty workspace
- [ ] Verify reasonable motions
- [ ] No erratic behavior
- [ ] Actions within expected range
- [ ] Monitor for 10+ minutes

---

### Gradual Deployment

#### Phase 1: Single Object, Easy Position
- [ ] Place object in known good position
- [ ] Run 10 episodes
- [ ] Monitor closely
- [ ] Success rate >50%
- [ ] No safety incidents

#### Phase 3: Single Object, Varied Positions
- [ ] Test 5-7 different positions
- [ ] Run 5 episodes per position
- [ ] Success rate >60%
- [ ] Consistent behavior

#### Phase 3: Multiple Objects
- [ ] Test with 2-3 objects
- [ ] Various sizes
- [ ] Run 20 episodes
- [ ] Success rate >70%

#### Phase 3: Full Deployment
- [ ] Realistic scenarios
- [ ] Extended operation (1+ hour)
- [ ] Success rate >70%
- [ ] Failure recovery working

---

### Monitoring & Maintenance

#### Continuous Monitoring
- [ ] Log all episodes
- [ ] Track success rate over time
- [ ] Monitor failure modes
- [ ] Check for degradation
- [ ] Review safety incidents

#### Regular Maintenance
- [ ] Daily: Visual inspection
- [ ] Weekly: Calibration check
- [ ] Monthly: Full recalibration
- [ ] Quarterly: Performance review

#### Data Collection
- [ ] Collect failure cases
- [ ] Periodically collect success cases
- [ ] Label and store for retraining
- [ ] Analyze trends

---

### Troubleshooting Guide

#### Low Success Rate (<50%)
1. Check camera calibration
2. Verify lighting conditions
3. Review domain randomization
4. Collect real data for fine-tuning

#### Erratic Behavior
1. Check action normalization
2. Verify safety layer active
3. Review recent changes
4. Test in simulation first

#### Gripper Failures
1. Calibrate gripper force
2. Adjust grasp positions
3. Check object properties
4. Review grasp detection logic

#### Collisions
1. Reduce action magnitude
2. Strengthen safety constraints
3. Add more collision training data
4. Review workspace setup
```

**ÏãúÍ∞Ñ: Ï£º 8-10ÏãúÍ∞Ñ**

---

### ÏÑ±Îä• ÏµúÏ†ÅÌôî

#### Ï∂îÎ°† ÏÜçÎèÑ ÏµúÏ†ÅÌôî
```python
# optimization.py

class ModelOptimizer:
    """
    VLA Î™®Îç∏ ÏµúÏ†ÅÌôî
    
    Î™©Ìëú:
    - Ï∂îÎ°† ÏÜçÎèÑ Ìñ•ÏÉÅ (< 100ms)
    - Î©îÎ™®Î¶¨ ÏÇ¨Ïö©Îüâ Í∞êÏÜå
    - Throughput Ï¶ùÍ∞Ä
    """
    
    def __init__(self, model):
        self.model = model
    
    def optimize_all(self):
        """
        Ï†ÑÏ≤¥ ÏµúÏ†ÅÌôî ÌååÏù¥ÌîÑÎùºÏù∏
        """
        # 1. TorchScript compilation
        print("Step 1: TorchScript compilation...")
        scripted_model = self.to_torchscript()
        
        # 2. Quantization
        print("Step 2: Quantization...")
        quantized_model = self.quantize(scripted_model)
        
        # 3. ONNX export (optional)
        print("Step 3: ONNX export...")
        self.export_onnx()
        
        # 4. TensorRT (NVIDIA)
        print("Step 4: TensorRT optimization...")
        trt_model = self.to_tensorrt()
        
        return trt_model
    
    def to_torchscript(self):
        """
        TorchScriptÎ°ú Î≥ÄÌôò
        
        Ïû•Ï†ê:
        - Python overhead Ï†úÍ±∞
        - ÏµúÏ†ÅÌôîÎêú Ïã§Ìñâ
        - Î∞∞Ìè¨ Ïö©Ïù¥
        """
        self.model.eval()
        
        # Example input
        dummy_obs = {
            'rgb': torch.randn(1, 3, 224, 224).cuda(),
            'proprio': torch.randn(1, 15).cuda()
        }
        
        # Trace model
        with torch.no_grad():
            scripted = torch.jit.trace(self.model, dummy_obs)
        
        # Save
        scripted.save('model_scripted.pt')
        
        print("‚úÖ TorchScript model saved")
        
        return scripted
    
    def quantize(self, model):
        """
        Î™®Îç∏ ÏñëÏûêÌôî (FP32 ‚Üí INT8)
        
        Ïû•Ï†ê:
        - Î™®Îç∏ ÌÅ¨Í∏∞ 1/4
        - Ï∂îÎ°† ÏÜçÎèÑ 2-4Î∞∞
        - ÏïΩÍ∞ÑÏùò Ï†ïÌôïÎèÑ ÏÜêÏã§ (<2%)
        """
        from torch.quantization import quantize_dynamic
        
        quantized = quantize_dynamic(
            model,
            {torch.nn.Linear},  # Quantize linear layers
            dtype=torch.qint8
        )
        
        # Save
        torch.save(quantized.state_dict(), 'model_quantized.pt')
        
        print("‚úÖ Quantized model saved")
        
        return quantized
    
    def export_onnx(self):
        """
        ONNXÎ°ú export
        
        Ïû•Ï†ê:
        - Îã§ÏñëÌïú runtime ÏßÄÏõê
        - Ï∂îÍ∞Ä ÏµúÏ†ÅÌôî Í∞ÄÎä•
        - ÌîåÎû´Ìèº ÎèÖÎ¶ΩÏ†Å
        """
        self.model.eval()
        
        dummy_obs = {
            'rgb': torch.randn(1, 3, 224, 224).cuda(),
            'proprio': torch.randn(1, 15).cuda()
        }
        
        torch.onnx.export(
            self.model,
            dummy_obs,
            'model.onnx',
            input_names=['rgb', 'proprio'],
            output_names=['actions'],
            dynamic_axes={
                'rgb': {0: 'batch'},
                'proprio': {0: 'batch'},
                'actions': {0: 'batch'}
            },
            opset_version=14
        )
        
        print("‚úÖ ONNX model exported")
    
    def to_tensorrt(self):
        """
        TensorRTÎ°ú Î≥ÄÌôò (NVIDIA GPU)
        
        Ïû•Ï†ê:
        - ÏµúÎåÄ Ï∂îÎ°† ÏÜçÎèÑ
        - GPU ÏµúÏ†ÅÌôî
        - Mixed precision
        """
        import tensorrt as trt
        from torch2trt import torch2trt
        
        self.model.eval()
        
        dummy_obs = {
            'rgb': torch.randn(1, 3, 224, 224).cuda(),
            'proprio': torch.randn(1, 15).cuda()
        }
        
        # Convert
        model_trt = torch2trt(
            self.model,
            [dummy_obs],
            fp16_mode=True,  # FP16 precision
            max_workspace_size=1 << 30  # 1GB
        )
        
        # Save
        torch.save(model_trt.state_dict(), 'model_trt.pth')
        
        print("‚úÖ TensorRT model saved")
        
        return model_trt
    
    def benchmark(self, model, num_iterations=100):
        """
        Ï∂îÎ°† ÏÜçÎèÑ Î≤§ÏπòÎßàÌÅ¨
        """
        import time
        
        model.eval()
        
        dummy_obs = {
            'rgb': torch.randn(1, 3, 224, 224).cuda(),
            'proprio': torch.randn(1, 15).cuda()
        }
        
        # Warmup
        for _ in range(10):
            with torch.no_grad():
                _ = model(dummy_obs)
        
        # Benchmark
        torch.cuda.synchronize()
        start = time.time()
        
        for _ in range(num_iterations):
            with torch.no_grad():
                _ = model(dummy_obs)
        
        torch.cuda.synchronize()
        end = time.time()
        
        avg_time = (end - start) / num_iterations * 1000  # ms
        
        print(f"Average inference time: {avg_time:.2f} ms")
        print(f"Throughput: {1000/avg_time:.1f} FPS")
        
        return avg_time

# Compare optimizations
def compare_optimizations():
    """
    ÏµúÏ†ÅÌôî Ìö®Í≥º ÎπÑÍµê
    """
    # Original model
    model = ACTPolicy(config).cuda()
    model.load_state_dict(torch.load('best_model.pt')['model_state_dict'])
    
    optimizer = ModelOptimizer(model)
    
    print("\n" + "="*60)
    print("OPTIMIZATION BENCHMARK")
    print("="*60)
    
    # Original
    print("\n1. Original Model (FP32)")
    time_original = optimizer.benchmark(model)
    
    # TorchScript
    print("\n2. TorchScript")
    scripted = optimizer.to_torchscript()
    time_scripted = optimizer.benchmark(scripted)
    
    # Quantized
    print("\n3. Quantized (INT8)")
    quantized = optimizer.quantize(model)
    time_quantized = optimizer.benchmark(quantized)
    
    # TensorRT
    print("\n4. TensorRT (FP16)")
    trt = optimizer.to_tensorrt()
    time_trt = optimizer.benchmark(trt)
    
    # Summary
    print("\n" + "="*60)
    print("SUMMARY")
    print("="*60)
    print(f"{'Method':<20s} {'Time (ms)':<12s} {'Speedup':<10s}")
    print("-"*60)
    print(f"{'Original':<20s} {time_original:>10.2f} ms {1.0:>8.1f}x")
    print(f"{'TorchScript':<20s} {time_scripted:>10.2f} ms {time_original/time_scripted:>8.1f}x")
    print(f"{'Quantized':<20s} {time_quantized:>10.2f} ms {time_original/time_quantized:>8.1f}x")
    print(f"{'TensorRT':<20s} {time_trt:>10.2f} ms {time_original/time_trt:>8.1f}x")
    print("="*60)

"""
ÏòàÏÉÅ Í≤∞Í≥º:

Method              Time (ms)    Speedup   
------------------------------------------------------------
Original                80.00 ms      1.0x
TorchScript             50.00 ms      1.6x
Quantized               40.00 ms      2.0x
TensorRT                25.00 ms      3.2x
============================================================

‚Üí TensorRT ÏÇ¨Ïö© Ïãú Ïã§ÏãúÍ∞Ñ Ï†úÏñ¥ Í∞ÄÎä• (10Hz)
"""
```

---

#### Action Smoothing
```python
# action_smoothing.py

class ActionSmoother:
    """
    Action smoothing for jerk reduction
    
    Î∞©Î≤ï:
    1. Moving average
    2. Exponential smoothing
    3. Savitzky-Golay filter
    """
    
    def __init__(self, method='exponential', window=5, alpha=0.3):
        self.method = method
        self.window = window
        self.alpha = alpha
        
        self.action_history = deque(maxlen=window)
    
    def smooth(self, action):
        """
        Smooth action
        """
        self.action_history.append(action)
        
        if self.method == 'moving_average':
            return self.moving_average()
        
        elif self.method == 'exponential':
            return self.exponential_smoothing(action)
        
        elif self.method == 'savgol':
            return self.savitzky_golay()
        
        else:
            return action
    
    def moving_average(self):
        """
        Moving average smoothing
        """
        if len(self.action_history) == 0:
            return np.zeros(7)
        
        return np.mean(list(self.action_history), axis=0)
    
    def exponential_smoothing(self, action):
        """
        Exponential smoothing
        
        smoothed = alpha * current + (1-alpha) * previous
        """
        if len(self.action_history) < 2:
            return action
        
        previous_smoothed = self.action_history[-2]
        smoothed = self.alpha * action + (1 - self.alpha) * previous_smoothed
        
        return smoothed
    
    def savitzky_golay(self):
        """
        Savitzky-Golay filter
        """
        from scipy.signal import savgol_filter
        
        if len(self.action_history) < self.window:
            return self.action_history[-1]
        
        # Convert to array
        history_array = np.array(list(self.action_history))
        
        # Apply filter
        smoothed = savgol_filter(
            history_array,
            window_length=self.window,
            polyorder=2,
            axis=0
        )
        
        return smoothed[-1]
```

**ÏãúÍ∞Ñ: Ï£º 4-6ÏãúÍ∞Ñ**

---

## Phase 3 ÏôÑÎ£å Ï≤¥ÌÅ¨
```
‚úÖ Isaac Sim ÌôòÍ≤Ω ÎßàÏä§ÌÑ∞
‚úÖ Action/Observation Space ÏÑ§Í≥Ñ
‚úÖ Î¨ºÎ•ò VLA Í∞úÎ∞ú ÏôÑÎ£å
‚úÖ Îç∞Ïù¥ÌÑ∞ ÏàòÏßë Î∞è ÌíàÏßà Í¥ÄÎ¶¨
‚úÖ VLA ÌïôÏäµ Î∞è ÌèâÍ∞Ä
‚úÖ Hyperparameter tuning
‚úÖ Ïã§Ìå® Î≥µÍµ¨ ÏãúÏä§ÌÖú
‚úÖ Safety layer Íµ¨ÌòÑ
‚úÖ ROS2 ÏôÑÏ†Ñ ÌÜµÌï©
‚úÖ Domain Randomization
‚úÖ Sim-to-Real Ï§ÄÎπÑ
‚úÖ ÏÑ±Îä• ÏµúÏ†ÅÌôî

ÏÑ±Í≥º:
- Success Rate: 70%+
- Ïã§ÏãúÍ∞Ñ Ï†úÏñ¥ Í∞ÄÎä• (< 100ms)
- ROS2 Lifecycle Ìå®ÌÑ¥ Ï†ÅÏö©
- ÏïàÏ†Ñ ÏãúÏä§ÌÖú ÏôÑÎπÑ
- Ïã§Ï†ú Î°úÎ¥á Î∞∞Ìè¨ Ï§ÄÎπÑ ÏôÑÎ£å
```
